\documentclass{llncs}

\usepackage{llncsdoc}
\usepackage{multirow}
\usepackage{caption}
\usepackage{url}

\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}
\usepackage{expex}

%
\begin{document}
%
\title{HFST---a System for Creating NLP Tools}
%
\author{Krister Lind\'{e}n \and Erik Axelson \and Senka Drobac \and Sam Hardwick \and\\
Tommi A Pirinen \and Miikka Silfverberg \and ...}

\institute{University of Helsinki\\
Department of Modern Languages\\
Unioninkatu 40 A\\
FI-00014 Helsingin yliopisto, Finland\\
\email{\{krister.linden, erik.axelson, senka.drobac, sam.hardwick,\\
tommi.pirinen, miikka silfverberg, ...\}@helsinki.fi}}

\maketitle

% Removed the manual bibstyle in favor of splncs03.bst,
% if it's required fetch it from svn history

\begin{abstract}
%Krister
\keywords{keywords here}
\end{abstract}


\section*{Introduction}
% Krister

\section{Applications and Tests}\label{hfst:structural-layout}
% Miikka

\subsection{Language identification}
Language identification is the task of recognizing the language of a
text or text fragment. It is highly useful in applications, that need
to process documents written in various languages where the language
might not be overtly marked in the document. For example a translation
application might need to identify the language of a document in order
to apply the correct translation model. Another example is a speller for
Finnish that might need to identify paragraphs that are written in
English, in order not to perform spell checking on the paragraphs.

In this section we outline how to use Hfst tagger tools and language
identification tools for creating language identifiers. We also
present an experiment on language identification for documents written
in Dutch, English, Estonian, Finnish, German or Swedish. The
experiment shows that Hfst language identifiers are highly accurate
(99.5\% of the input sentences were correctly classified).

There are several methods for performing language
identification. Highly accurate language identification can be
accomplished by treating documents as letter sequences and training
Markov chain from training documents whose language is
known~\cite{cavnar/1994}. One Markov chain is trained for each
language that the system recognizes. Language identification consists
of applying each Markov chain on input and choosing the language whose
model gives the highest likelihood for the text. 

Hfst language identifiers adopt a Markov chain framework, which can be
implemented using weighted finite-state technology. Using Hfst tagger
tools~\cite{silfverberg/2011}, we train Markov models for all
languages. A separate program, {\tt hfst-guess-language}, reads the
models and input text and labels each sentence with the language,
whose model gave the highest likelihood for the sentence.

We present an experiment on applying Hfst language identifiers for
guessing the language of sentences written in six languages. For all
languages except Swedish, we used training data from corpora
containing newspaper text. For Swedish, we used more general text.

For Dutch we used the Alpino treebank~\cite{bouma/2000}, for English
we used the Penn Treebank~\cite{marcus/1993}, for Estonian we used the
Estonian National
Corpus~\footnote{http://www.cl.ut.ee/korpused/segakorpus/}, for
Finnish we used text from the largest Finnish newspaper Helsingin
Sanomat year 1995~\footnote{http://www.csc.fi/kielipankki/}, for
German we used the TIGER Corpus~\cite{brants/2002} and for Swedish we
used Talbanken~\cite{einarsson/1976}.

\begin{table}
\begin{center}
\begin{tabular}{l|cc}
Language & Train data (utf-8 chars) & Test data (utf-8 chars)\\
\hline
Dutch    & 245,000  & 24,000\\
English  & 265,000  & 26,000\\
Estonian & 238,000  & 23,000\\
Finnish  & 155,000  & 14,000\\
German   & 280,000  & 28,000\\
Swedish  & 164,000  & 16,000\\
\end{tabular}
\caption{For each language, we used 2000 sentences for training and
  200 sentence for testing. We give the sizes of the data sets in
  utf-8 characters.}\label{tab:lang-id-data}
\end{center}
\end{table}

For each language, we chose 2200 sentences for training and
testing. Of the sentences, every eleventh sentence was used for
testing and the rest for training. This totals 2000 sentences for
training and 200 sentences for testing for each language. The sizes of
the data sets in utf-8 characters are described in
Table~\ref{tab:lang-id-data}. The average length of a sentence in
characters was shorter for Finnish and Swedish than for the other
languages.

\begin{table}
\begin{center}
\begin{tabular}{l|l}
Language & Accuracy\\
\hline
Dutch    & ~~~99.0\%\\
English  & ~~~99.5\%\\
Estonian & ~~~99.5\%\\
Finnish  & ~~~99.5\%\\
German   & ~~100.0\%\\
Swedish  & ~~~99.5\%\\
\hline
ALL      & ~~~99.5\%
\end{tabular}
\caption{We give accuracy of the language guesser per language and for
  all languages.}\label{tab:lang-id-acc}
\end{center}
\end{table}

We ran the language identifier for test sentences from all six
languages (totally 1200 sentences) and computed the accuracy of the
language identification system as the $corr / all$, where $corr$ is
the number of sentences whose language was correctly guessed and $all$
is the number of all sentences. In Table~\ref{tab:lang-id-acc}, we
show results for each individual language and all languages
combined. 

Of all sentences, 99.5\% were correctly classified, which demonstrates
that the language identifiers are highly accurate. This is encouraging
because Finnish and Estonian have similar orthographies. This applies
to German, Swedish and Dutch as well.

Currently identification is limited to identifying the closest
language corresponding to a sentence. There is no option to label a
sentence as belonging to an unknown language. It could be possible to
apply some threshold likelihood $l(n)$ which would state that a model
has to give a sentence of $n$ characters at least likelihood $l(n)$,
in order for the sentence to be labeled as belonging to the language
of the model. 

In practice it has been very difficult to establish $l(n)$ in a
reliable way. It is likely to be dependent on the genre of the
document, which makes it less useful. Identifying unknown language
using Hfst language identifiers thus remains future work.

\subsection{Morphologies and Guessers}
\label{sec: morph-guessers}
% Juha, Miikka

Language technological applications for agglutinating languages like
Finnish and Hungarian benefit greatly from high coverage morphological
analyzers, which supply word forms with their morphological
analyses. This makes applications dependent on the coverage of the
morphological analyzer. Building a high coverage morphological
analyzer (with recall over 95\%) is a substantial task and even with a
high coverage analyzer domain specific vocabulary presents a
challenge. Therefore accurate methods for dealing with out of
vocabulary words are needed.

Using Hfst tools it is possible to use an existing morphological
analyzer to construct a morphological guesser based on word
suffixes. Suffix based guessing is sufficient for many agglutinating
languages such as Finnish~\cite{linden/2009/nodalida}, where most
inflection and derivation is marked using suffixes. Even if a word is
not recognized by the morphological analyzer, the analyzer is likely
to recognize some words which inflect similarly as the unknown
word. These can be used for guessing the inflection of the unknown
word.

Guessing of an unknown word like ``twiitin'' (the genitive form of
``twiitti'' tweet in Finnish) is based on finding the recognized word
forms like ``sviitin'' (genitive form of ``sviitti'' hotel suite in
Finnish), that have long suffixes such as ``-iitin'', which match the
suffixes of the unrecognized word. The longer the common suffix, the
likelier it is that the unrecognized word has the same inflection as
the known word. The guesser will output morphological analyses for
``twiitin'' in order of likelihood.

Besides the length of the matching suffix, guesses can also be ordered
based on the probability that a suffix matches a given analysis. This
can be estimated using a labeled training corpus. In addition, any
existing weighting scheme in the original morphological analyzer can
be utilized.

If the morphological analyzer marks declension class, the guesser can
also be used for guessing the declension class. If the declension
class is marked, the guesser can be used for generation of word forms
as well as analysis. This is described in
Section~\ref{sec:morph-generation}.

Constructing a morphological guesser from
OMorFi~\footnote{http://code.google.com/p/omorfi/} The open-source
Finnish morphology~\cite{pirinen/2008}, the three top guesses for
``twiitin'' are (the markup is slightly simplified): \small
\begin{verbatim}
  twiit  [POS=NOUN] [GUESS_CATEGORY=5]  [NUM=SG][CASE=GEN]
  twiiti [POS=NOUN] [GUESS_CATEGORY=33] [NUM=SG][CASE=NOM]
  twiit  [POS=VERB] [GUESS_CATEGORY=53] [VOICE=ACT][MOOD=INDV] ...
\end{verbatim}
\normalsize
The first field corresponds to the stem of the word, the second field
to its main part of speech and the third to its declension class. The
fourth field shows the inflectional and derivational information of
the guess. In this case, the first guess is correct. It is modeled
after declension class number 5, which is a class of nouns containing
among others the noun ``sviitti''.


More stuff to write about:
\begin{itemize}
\item Experiment for Finnish. How often is the first guess correct?
  How often is the correct answer among the three best guesses?
\item Using the guesser for extending the lexicon.
\item More?
\end{itemize}

\subsection{Spell-checking}
% Tommi

Using weighted finite-state methods in performing spell-checking and correction 
is a relatively recent branch of study in spell-checking research. The concept
is simple: finite-state morphological analysers and such can be trivially ported
into spell-checking dictionaries providing a language model for the correctly
spelled words in the spell-checking system. A baseline finite-state model for
correcting spelling errors can be inferred from the language model by creating
a Levenshtein-Damerau automaton based on the alphabetic characters present in
the language. The language model can be simply trained to prefer more common
words when the Levenshtein-Damerau distance between to suggestions is the same.
This is done by basic unigram language model training that simply maximises
the frequency of the suggested word. To our experience, even relatively moderate
training material will gain improvement in quality as the statistical training
improves the discriminative power of the model, and the likelihood of random
typing error is more likely in frequent words.

The practical process of creating a finite-state spell-checker and corrector
is really simple: given an analysator capable of recognising correctly spelled
word-forms of a language, take a projection to the surface forms to create a
single-tape automaton. The automaton is trained with corpus word-form list, 
where end-weight of each word-form is e.g. $-\log\frac{c(wf)}{CS}$, where 
$c(wf)$ is the count of word-forms, and $CS$ is the corpus size. Words not
found in the corpus are given some weight $w_{max} > -\log\frac{1}{CS}$ to
push them in the bottom of the suggestion list; this weighting can be done
in finite-state algebra by composition of weighted $\Sigma^{\star}$ language,
or by manually fixing the data structure.

The error model can be improved from the baseline Levenshtein-Damerau distance
metric as well. For this purpose we need an error corpus, that is, a set of
errors with their frequencies. This can be semi-automatically extracted from
weakly annotated sources, such as Wikipedia. From Wikipedia we get, among tons
of other things, word-to-word corrections. It is possible to use the specific
word-to-word corrections to create simple extension of common confusables to
error model. Another way is to re-align the corrections using the
Damerau-Levenshtein algorithm, and train the original distance measure with
frequencies of the corrections in same manner as we did for word-forms above.

As an example of simplicity of this process, we have obtained an open source
German morphological analyser
morphisto~\footnote{\url{http://code.google.com/p/morphisto/}} to generate a
spelling checker, trained it with word-forms extracted from German
Wikipedia~\footnote{\url{http://de.wikipedia.org}} and applied it to Wikipedia
data to find spelling errors and correct them. The whole
script to do this is in our version control~\footnote{\url{}}, and it took us
no more than one work day by one researcher to implement this application.
The resulting system does spell-checking and correction with baseline
finite-state edit distance algorithm~\cite{pirinen/2010finitestate} applying
up to 2 errors per word-form at speed of 100,000~word-forms per second.

\subsection{Named Entity Recognition}
% Jyrki, Juha (Sam?)

An important application of the Pmatch tool is named-entity
recognition (NER). Toy examples of named-entity recognition with
Pmatch were presented by Karttunen \cite{karttunen/2011}. We have
converted a full-scale named-entity recognizer for Swedish to use the
HFST implementation of Pmatch, and we are writing one for Finnish.

A named-entity recognizer marks names in a text, typically with
information on the type (category) of the name. \textsf{[Ref?]} Major
types of names include persons, locations, organizations, events and
works of art. NER tools may also recognize temporal and numeric
expressions. Names and their types can be recognized based on internal
evidence, i.e. the structure of the name itself (e.g., \textit{ACME
  Inc.} probably denotes a company), or based on external evidence,
i.e. the context of the name (e.g., \textit{she works for ACME};
\textit{ACME hired a new CEO}). \textsf{[Ref: McDonald 1996?]} In
addition, NER tools typically use gazetteers, lists of known names, to
ensure that common names are recognized with the correct type.
\textsf{[Is this general description of NER needed?]}

A key feature of Pmatch making it well-suited for NER is the ability
to add XML-style tags around substrings matching a regular expression,
as in \cite{karttunen/2011}. Such tagging regular expressions are
specified by suffixing the expression with
\texttt{EndTag(\textit{TagName})}. For example, the following regular
expression \texttt{CorpSuffix} (with auxiliary definitions) marks
company names ending in a company designator:

\begin{verbatim}
Define NSTag [? - [Whitespace|"<"|">"]] ;
Define Aa ["A"|"a"] ;
...
Define Zz ["Z"|"z"] ;
Define CorpSuffix
    [UppercaseAlpha NSTag+ " "]+
    ["HB" | Aa Bb | Aa "." Bb "." | Cc Oo | Ii "nc" | Ll Tt Dd
     | "AG" | "A.S." | "A/S" | "AS" | "ADR" | "Corp" | "Gmb" Hh
     | "Hld" | "Limited" | "N.V." | "Oy" | "S.A." | "SA" | "BV"]
    EndTag(EnamexOrgCrp) ;
\end{verbatim}

\begin{sloppypar}
The built-in set \texttt{Whitespace} denotes any whitespace character
and \texttt{UppercaseAlpha} any uppercase letter. String literals are
enclosed in double quotes where Karttunen's FST uses curly braces
\cite{karttunen/2011}.
\end{sloppypar}

For matching, Pmatch considers the regular expression with the special
name \texttt{TOP}. Thus, to be able to tag the company names with the
expression \texttt{CorpSuffix} above, \texttt{TOP} must refer to it:

\begin{verbatim}
Define TOP ... | CorpSuffix | ... ;
\end{verbatim}

The expression can now tag the company names in the following input
text:

\begin{verbatim}
Computer Systems Corp announced a merger with Home Computers Inc .
\end{verbatim}

\noindent
The result is:

\begin{verbatim}
<EnamexOrgCrp>Computer Systems Corp</EnamexOrgCrp> announced a
merger with <EnamexOrgCrp>Home Computers Inc</EnamexOrgCrp> .
\end{verbatim}

Pmatch outputs as such the parts of input that do not match the
regular expression or that match a part of the expression without an
\texttt{EndTag}.

In general, a Pmatch expression set (file) contains a list of named
regular expression definitions of the form \texttt{Define
  \textit{name} \textit{regex} ;}. The regular expression
\texttt{\textit{regex}} may contain references to other named regular
expressions.

Pmatch considers leftmost longest matches of \texttt{TOP} in the input
and adds the tags specified in \texttt{TOP} or the expressions to
which it refers. If several subexpressions match the same leftmost
longest match, it is unspecified (but deterministic) which one Pmatch
chooses. To disambiguate between matches, context expressions can be
added to the matching regular expressions. This case may arise when
one expression is an exception to a more general rule. In such a case,
the exception expression can be subtracted from the general one.
\textsf{[Example?]}

\textsf{[Is this correct? Should this rather be in the technical
  description of Pmatch?]}

An \texttt{EndTag} expression may be accompanied with a context
expression specifying that the tags should only be added if the
context of the match matches the context expression. For example, the
following expression tags the capitalized words following
\textit{rörelseresultatet för} (`operating profit of') with
\texttt{EnamexOrgCrp}:

\begin{verbatim}
Define CapWord2 UppercaseAlpha NSTag+ ;
Define OrgCrpOpProfit
    CapWord2 [" " CapWord2]*
    EndTag(EnamexOrgCrp)
    LC(Rr "örelse" ["resultatet" | "förlust"] " för ") ;
Define TOP ... | OrgCrpOpProfit | ... ;
\end{verbatim}

\noindent
For example

\begin{verbatim}
Rörelseresultatet för <EnamexOrgCrp>Computer Systems</EnamexOrgCrp>
var ...
\end{verbatim}

As in \cite{karttunen/2011}, the regular expression in \texttt{LC()}
specifies a left context that must precede the actual match for the
match to be considered and the tags added. Similarly, \texttt{RC()}
specifies a right context that must follow the match. \texttt{NLC()}
and \texttt{NRC()} are negative left and right context, respectively:
the match is considered only if not preceded (or followed) by the
negative context.

Context expressions may be combined with conjunction and disjunction.
For example, the following expressions mark a capitalized word ending
in an \textit{s} as a sports organization (\texttt{EnamesxOrgAth}) if
it is preceded by \textit{in} and followed by \textit{segermål}
(`winning goal'):

\begin{verbatim}
Define OrgAthWingoal
    CapWord2 "s" EndTag(EnamexOrgAth) LC(" in ") RC(" segermål") ;
Define TOP ... | OrgAthWingoal | ... ;
\end{verbatim}

\textsf{[Example of disjunctive contexts?]}

Conjunctive contexts can also be specified at several stages in the
expressions. For example, a name is marked as a sports event by the
following expressions only if it is followed by a space and
\textit{spelades} (`was played') (right context expression from
\texttt{EvnAtlIntl}) and preceded by a space or sentence boundary
(\texttt{\#}) (left context expression from \texttt{TOP}).

\begin{verbatim}
Define EvnAtlIntl
    [CapWord2 " "]+ "International "
    EndTag(EnamexEvnAtl)
    RC(" spelades") ;
Define TOP [ ... | EvnAtlIntl | ... ] LC(Whitespace | #) ;
\end{verbatim}

\noindent
In this case, the left context condition in \texttt{TOP} is considered
for all the \texttt{EndTag} expressions contained or included in
\texttt{TOP}.

HFST Pmatch regular expressions may contain transductions that can add
extra output or discard specified parts of the input. Even though they
are not in general used in tagging regular expressions, they can be
used in correction expressions that modify previously added tags. For
example, the following expressions move the start tag by removing the
existing tags and adding new ones using \texttt{EndTag}:

\begin{verbatim}
Define LowerWord LowercaseAlpha+ ;
Define NoTags [? - ["<"|">"]]+ ;
Define StartTagPrsHum "<EnamexPrsHum>" ;
Define RemoveStartTagPrsHum
    StartTagPrsHum> .o. [StartTagPrsHum -> ""] ;
Define EndTagEnamex "</Enamex" [? - ">"]+ ">" ;
Define RemoveEndTag [EndTagEnamex .o. [EndTagEnamex -> ""]] ;
Define TOP
    RemoveStartTagPrs LowerWord " " CapWord2 "s "
    [Vv Dd " " NoTags RemoveEndTag EndTag(EnamexPrsHum)] ;
\end{verbatim}

For example, this corrects

\begin{verbatim}
... <EnamexPrsHum>säger Computers vd Svensson<EnamexPrsHum>
\end{verbatim}

\noindent
(`says Computer's CEO Svensson') to

\begin{verbatim}
... säger Computers vd <EnamexPrsHum>Svensson<EnamexPrsHum>
\end{verbatim}

The Swedish named-entity recognizer works on tokenized running text
input: punctuation marks are separated from words by spaces but the
words are not annotated in any way. In contrast, the forthcoming
Finnish NER tool will work on annotated text, which makes it easier to
write more general rules, in particular for a morphologically rich
language such as Finnish.

The original implementation of the Swedish named-entity recognizer
\cite{kokkinakis/2003} contained 24 different recognizers running in a
pipeline and a correction filter run after each stage. 21 of the
recognizers and the correction filter had been written using
Flex\footnote{http://flex.sourceforge.net/} rules; the remaining three
were Perl scripts recognizing names in gazetteers. The Flex rules
recognize regular expression matches in text, corresponding to names
and their possible context, and the actions of the rules mark the name
part of the match with XML elements. The correction filter modifies
the tags of the elements to remove incorrectly marked names, to
include words in the context in names, to exclude incorrectly included
parts of names, to split names into two, to mark new names based on
marked names in the context, and to change the type of a name.
\textsf{[How much (or little) should we describe the original
    implementation?]}

Incentives for reimplementing the Swedish recognizer in Pmatch
included the slow compilation of some of the Flex rule sets (several
hours in the worst case), which makes it time-consuming to test
changes to the rules, and the wish to be able to use a single tool or
formalism for all components of the recognizer.

Since both Flex and Pmatch are based on regular expressions and
recognizing the leftmost longest match, we were able to automate a
large part of the conversion from Flex rules to Pmatch rules. The
conversion script also analysed the Flex actions to find out which
part (words) of the recognized match was to be marked as a name and
which was context. The correction filter was converted by hand, since
its actions were more varied and would have required more elaborate
processing than those in the recognizers.

However, differences in the semantics of Flex NER rules and Pmatch
meant that the Pmatch expressions generated by the automatic
conversion had to be edited by hand to work correctly. Firstly, the
Flex rules were written so that the matched regular expressions cover
the contexts in addition to the name to be recognized, whereas Pmatch
excludes contexts from the leftmost longest match. Consequently, the
leftmost longest match at a certain point in text may be found by
different patterns in Flex and Pmatch. \textsf{[Add an example of the
  consequences]}

Secondly, Flex rules are ordered whereas Pmatch expressions are not.
This means that the Flex patterns can be ordered from the most
specific to the most general, so that the most specific pattern is
chosen even if also a more general pattern would match. In contrast,
Pmatch cannot guarantee any specific order: if more than one
expression have the same leftmost longest match, an arbitrary
expression is chosen, though always the same for the same set of
expressions. The ordering has to be replaced with more detailed
contexts or regular language difference or both. For example, to
prevent capitalized ``järnväg'' (`railway') from matching a more
general expression marking street names, it is subtracted from the
more general pattern:

\begin{verbatim}
Define LocStrSweExcept "Järnväg" ("en") | "Omväg" ("en") | ... ;
Define LocStrSwe
    [Capword2 ["väg" ("en") | "gata" ("n")]] - LocStrSweExcept
    EndTag(EnamexLocStr) ;
\end{verbatim}

The gazetteer lookup of the original implementation of the Swedish NER
marks words found in the gazetteer not only as such but also, for
example, names with an inflectional suffix, names with another name
prefixed with a dash or slash, and lowercased names of at least five
letters. The gazetteers of the original implementation contain pairs
of names and their types, but to make the Pmatch implementation more
efficient, the names have been divided into files by name type. The
Pmatch rules read these files as disjunctions of strings with the
\texttt{@txt"\textit{filename}"} construct. The basic Pmatch rules for
the gazetteer lookup are as follows:

\begin{verbatim}
Define NSTag [Alpha|Num] | [? - [Whitespace|"<"|">"]] ;
! Names as such
Define LocStrBasic @txt"gaz-LocStr.txt" EndTag(EnamexLocStr) ;
Define PrsHumBasic @txt"gaz-PrsHum.txt" EndTag(EnamexPrsHum) ;
...
! Names with an inflectional suffix
Define Suffix ["s" | ":" LowercaseAlpha+] ;
Define LocStrSuffix
    @txt"gaz-LocStr.txt" Suffix EndTag(EnamexLocStr) ;
...
! Words with a prefixed word
Define PrefixWord UppercaseAlpha NSTag+ ["/"|"-"] ;
Define LocStrPrefixWord 
    PrefixWord @txt"gaz-LocStr.txt" EndTag(EnamexLocStr) ;
...
Define Boundary [" " | #] ;
Define TOP
    [  LocStrBasic | PrsHumBasic | ... | LocStrSuffix | ... 
     | LocStrPrefixWord | ... ]
    LC(Boundary) RC(Boundary);
\end{verbatim}

The context conditions in \texttt{TOP} allows names to be recognized
only at word boundaries.

Compiling the Pmatch version of the Swedish NER was about ten times
faster than that of the Flex version, so the goal of speeding up the
compilation was largely achieved. However, it seems to take about
three times as much time to process text with Pmatch NER than with
Flex NER. This speed also required the use of a left context condition
of a whitespace or sentence boundary; without the context, the running
times were many times longer. The total size of the current Pmatch
FSTs is over three gigabytes, about eight times as large as the
executables compiled from the Flex files, but we will investigate ways
to reduce their size. \textsf{[Should we have more precise figures,
  even though the current results are still rather preliminary?]}

\subsection{Language Generation for Unknown words}
\label{sec:morph-generation}
Natural language user interfaces like dialogue systems, need a
language generation component for generating messages for the
user. The aim is to supply the user with information about the
internal state of some data base such as airline connections or
weather phenomena.

Language generation systems for agglutinating languages will benefit
from morphological analyzers, because generating syntactically correct
sentences requires inflecting words according to syntactic
context. Depending on the domain and coverage of the morphological
analyzer, it might also be necessary to inflect words that are not
recognized by the morphological analyzer. 

Hfst morphological guessers presented in Section~\ref{sec:
  morph-guessers} can be used for generation as well as morphological
analysis. For example using the OMorFi morphology for Finnish, the
best morphological guess for the unknown word ``twiitin'' is
\begin{verbatim}
  twiit  [POS=NOUN] [GUESS_CATEGORY=5]  [NUM=SG][CASE=GEN]
\end{verbatim}
Replacing the inflectional information {\tt [NUM=SG][CASE=GEN]}
(singular genitive case) by {\tt [NUM=PL][CASE=PAR]} (plural
partitive case) gives the analysis
\begin{verbatim}
  twiit  [POS=NOUN] [GUESS_CATEGORY=5]  [NUM=PL][CASE=PAR]
\end{verbatim}
which can be fed back to the guesser to generate the surface forms
``twiitteja'' and ``twiittejä''. The latter one is correct, though the
first one would also be possible in theory, since the variation
between ``-ja'' and ``-jä'' is governed by Finnish vowel harmony and
the stem ``twiit'' is neutral with respect to vowel harmony.

Besides language generation, morphological form generation is useful
when adding new entries to a morphological analyzer. For a human
expert it is easy to identify whether the word forms in a generated
list are the correct ones. It would also be possible to search a
corpus for the generated word forms, which can give a clue of whether
the generated forms constitute actual words and therefor also give a
clue about whether the guessed morphological analysis is the correct
one.

\section{Examples for User Environments}

\subsection{An Interface in Python}
% Erik, Tommi

In addition to an API library and command line tools, HFST library can
also be used through SWIG-generated python bindings. The bindings are
offered for python programming language versions 2 and 3. All HFST
functionalities are available via both versions, but the python
interpreters themselves have some differences. For example, Python 2
allows HFST exceptions to be caught directly, but python 3 requires
the use of a special wrapper function written as a part of the
bindings. On the other hand, python 3 has better support for unicode
characters, so it is probably a better choice for most linguistic
applications.

Below is an example of iterating through the states and transitions of
an HFST transducer using python bindings:

\begin{verbatim}
# Go through all states in fsm       
for state in fsm.states():
    # Go through all transitions                                               
    for transition in fsm.transitions(state):
        # do something
\end{verbatim}

And the same using HFST API directly:

\begin{verbatim}
// Go through all states in fsm
for (HfstBasicTransducer::const_iterator it = fsm.begin();
       it != fsm.end(); it++ )      
    {      
     // Go through all transitions    
    for (HfstBasicTransducer::HfstTransitions::const_iterator tr_it  
           = it->begin(); tr_it != it->end(); tr_it++) 
        {
        // do something
        }
    }
\end{verbatim}

The python bindings in particular make it smooth to use language models
developed for HFST in rapid prototyping of advanced tools. For an example, a
chunker for Finnish language was developed by simply bracketing adjacent
agreeing cases and few other similar expressions with basically few lines of
code on top of existing morphological analysers. E.g.  given Finnish sentence
``miljoona kärpästä voi olla väärässä paikassa'' we get bracketing all three
phrases bracketed by really simple python based bracketing that are illustrated
in following figure gloss:

\ex
\begingl
\gla Miljoona$_1$ kärpästä$_1$ voi$_2$ olla$_2$ väärässä$_3$ paikassa$_3$//
\glb Million-{\sc Num} fly-{\sc Par} can-{\sc AuxV} be-{\sc Inf} wrong-{\sc Ine} place-{\sc Ine}//
\glft `Million flies can be in a wrong place' //
\endgl
\xe

The rules governing chunking are all about pairs of words here: measurement
phrase is a numeral followed by a partitive nominal, verbal phrase is an
auxiliary followed by a lexical verb and noun phrase is an adjective and a noun
in any agreeing case.  The three pairs of words can be identified as common
chunks of Finnish language and having specific rules for these specific pairs
will give reasonable baseline surface syntax for applications where more
elaborate syntax structure is not required.

\subsubsection{A Chatroom Morphology tool}
% Sam

\subsection{HFST on Unix, Mac and Windows}
% Erik, Tommi

Portability has been one of the design goals of HFST system. The
current versions are available or compilable on all POSIX-supporting
systems, including Linuxes, Mac OS X and Cygwin under Windows
system. Compilation is also possible on MinGW under Windows.

Fresh version of HFST source code can be fetched from our svn
repository at Sourceforge. We also offer, usually twice a month, new
release packages that include source tarball (compilable on all
aforementioned platforms), Debian binaries (for Linux), MacPort
distribution (for MacOS X) and NSIS installer (for Windows).

Another layer of portability is attained by HFST's programming
language bindings via SWIG. It is possible to use full HFST library
through it's SWIG interfaces in all supported systems with python
versions 2 and 3.


\subsection{Other user-oriented items}
% Erik

We have four new command line tools. The most important are the XFST
parser hfst-xfst and the tagging tool hfst-tagger. Also two functions
that were earlier available only through the API can now be used via
command line tools: hfst-shuffle and hfst-prune-alphabet. The existing
tools also have new features: hfst-fst2txt can write to dot/graphviz
and PCKIMMO format and hfst-fst2strings has a new parameter that
controls its output to achieve better interoperability with other
command line tools.

Special symbols can be controlled better as we have added a parameter
to binary operators that controls whether unknown/identity transitions
are expanded, the default being true. We also have a new special
symbol, the default symbol that matches any symbol if no other
transition in a given state matches.

We have kept the number of dependencies in HFST as low as possible.
All back-ends (SFST, OpenFst and foma) are now bundled with
HFST. There is no more need to install them separately or worry about
having the right version. We can also make modifications to the
back-end libraries, for instance some of the warnings in back-end
libraries that are given during compilation are now fixed or
suppressed. GNU- and bash-specific commands were also removed from
scripts to make them more portable.

\section{Under the Hood}

\subsection{An independent XFST module}
% Erik (Erik)

HFST command line tools include an XFST parser tool that can be used
in interactive mode or to compile scriptfiles. The tool implements the
same functionalities as the original XFST (Xerox Finite-State Tool)
which is a general-purpose utility for computing with finite-state
networks. There are over 100 commands in hfst-xfst, the same as in the
Xerox tool. Below is an example of using hfst-xfst in interactive mode
where we define two transducer variables, use them in a regular
expression and print random words recognized by the expression.

\begin{verbatim}
$ hfst-xfst2fst 
hfst[0]: define Foo foo;
hfst[0]: define Bar bar;
hfst[0]: regex [[Foo|0] baz [Bar|0]];
? bytes. 4 states, 4 arcs, ? paths
hfst[1]: print random-words
baz
bazbar
foobaz
foobazbar
hfst[1]: 
\end{verbatim}

To test hfst-xfst, we have compiled 17 out of the 22 XFST exercises
that are found in the homepage of Beesley and Karttunen's book Finite
State Morphology. We have omitted the exercises that do not include an
answer and are not trivial to solve. We have compiled the exercises
using both Xerox's XFST and HFST's hfst-xfst and compared the results
for equivalence. For some exercises, we also have an additional
solution that uses hfst command line tools (other than hfst-xfst).

\subsection{XFST regexp compilation}
% Senka, Miikka

Restriction rules have been added to the regex parser.

Building restriction rules:

\begin{verbatim}
  define U [ ? - %<D%> ] ;

  define CENTER [ x y | x x y y ];

  Contexts:
  define L1 [ a ] ;
  define R1 [ b ] ;

  define L2 [ x ] ;
  define R2 [ y ] ;
  
Surround center with marks:
  define CEN1 [ U* %<D%> CENTER %<D%> U* ] ;

Put mark in context:
  define RES1 [ U* L1 %<D%> U* %<D%> R1 U* ] ;
  define RES2 [ U* L2 %<D%> U* %<D%> R2 U* ] ;
  
  
  define NODU [ U | 0:%<D%> ]* ;
  define NODL [ U | %<D%>:0 ]* ;

 
  regex U* - [ NODU .o. [ CEN1 - [ RES1 | RES2 ] ] .o. NODL ] ;
\end{verbatim}     
        
Before and after:

a and b are languages (automata)

Before ( a < b ):

\begin{verbatim}
~[?* b ?* a ?*]
\end{verbatim}

After ( a > b ):

\begin{verbatim}
~[?* a ?* b ?*]
\end{verbatim}

\subsection{Pmatch with applications for NER}
% Sam

\subsection{Other HFST development tools}
% Erik

\section{Discussion}\label{hfst:discussion}

\subsection{HMM vs. CRF for English and Finnish taggers}
% Miikka

\subsection{Adding rules to statistical systems (taggers and parser)}
% Miikka

\section{Conclusion}\label{hfst:conclusion}

\subsubsection*{Acknowledgments}

\bibliographystyle{splncs03}
\bibliography{sfcm-2013}

\end{document}
% vim: set spell:
