\documentclass{llncs}

\usepackage{llncsdoc}

%% PDFLaTeX
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{textcomp}      % for ° symbol
\usepackage{multirow}
\usepackage{caption}
\usepackage{url}
\usepackage{tabularx}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{mathptmx}
\usepackage{latexsym}
\usetikzlibrary{automata,positioning}
\usepackage{framed}
\usepackage{gb4e}
\usepackage{float}
\restylefloat{table}

%% XeLaTeX
% \usepackage{fontspec}
% \usepackage{xunicode}
% \usepackage{xltxtra}

\usepackage{expex}

%
\begin{document}
%
\title{Using HFST--Helsinki Finite-State Technology \\for Recognizing Semantic Frames}
%
\author{N.N. and N.N.}

 \institute{xx\\
 yy\\
 zz\\
 ww\\
 \email{\{n.n., n.n.\}@xxx.yy}}

\maketitle

% Removed the manual bibstyle in favor of splncs03.bst,
% if it's required fetch it from svn history

\begin{abstract}
%Krister
To recognize semantic frames in languages with a rich morphology, we need computational morphology.  
In this paper, we look at one particular framework, HFST--Helsinki Finite-State Technology, and how to
use it for recognizing semantic frames in context.
HFST enables tokeniztion, morphological analysis, tagging and frame annotation in one single framework.
\end{abstract}

\section*{Introduction}
% Krister (1 p.)
Language technology enables text
mining, e.g. by recognizing semantic frames. In this
paper we will look at one particular framework, HFST--Helsinki
Finite-State Technology, and its use in processing text from tokenization to recognizing
semantic frames in context.

HFST--Helsinki Finite Technology is a framework for building
morphologies including morphological lexicons \cite{hfst-pmatch}, \cite{hfst/2011}, \cite{linden/2009/sfcm}.
We present how HFST \emph{identifies semantic frames in context}.  
To do so, we first present how HFST supports building tokenizers and taggers, which is the minimum
requirement for recognizing semantic frames in languages with a rich morphology.  
In Section~1, we get an overview of the HFST p-match syntax and some examples of how to develop a
tokenizer based on a lexicon containing multi-word expressions.
In Section~2, we get an introduction to
building morphological taggers with HFST using machine learning. In Section~3, we get an introduction to
semantic frame recognition with HFST. In Section~4, we get a brief evaluation
of developing a rule set for semantic frame annotation. In Section~5, we discuss our results compared with other approaches
to semantic frame annotation.
In Section~6, we conclude the presentation.

\section{Tokenization using {\tt hfst-pmatch}}\label{sec:tokenization}
% Sam (4 p.)
Tokenization is a necessary first step in most text-based natural language processing tasks. For some
languages, e.g. English, it is often considered to be a mechanical
preprocessing task without linguistic importance, and for others, e.g. Chinese,
it is an intricate task called segmentation. However, even in languages that generally insert spaces between words, there
are issues that influence the quality or feasibility of tools down the
pipeline. We may, for example, want to be able to identify multi-word units,
identify compound words and mark their internal boundaries, control various
dimensions of normalization, or produce possible part-of-speech tags or
deeper morphological analyses. We describe a general approach to these issues based on morphological
transducers, regular expressions and the pattern matching operation
\verb+pmatch+~\cite{karttunen/2011}.

\subsection{A Short Introduction to {\tt pmatch}}

\verb+pmatch+~\cite{hfst-pmatch} is a pattern-matching operation for text based
on regular expressions. In HFST, it has been further developed from the ideas in Xerox
\verb+fst+. The regular expressions, i.e. \emph{rules}, are named, and are
invoked ultimately by a root expression , i.e. the \emph{top level}, which by convention
has the name \verb+TOP+. Expressions may refer to themselves or each other
circularly by special arcs which are interpreted at runtime, allowing
context-free grammars to be expressed.

Matching operates in a loop, accepting the largest
possible amount of input from the current position, possibly modifying it
according to the rules and tagging left and right boundaries of sub-rules, and
continuing on the the next position in the input. 
When the rules successfully accept (and possibly transform) some length of
input, that is a \emph{match}.
When the match has triggered the operation of a tagging directive, e.g. 
\verb+EndTag(TagName)+ or \verb+[].t(TagName)+, the enclosed length of the input is tagged with \emph{TagName}. 
For example, here is a very naïve tokenizer for English

\begin{center}
  \begin{framed}
\begin{verbatim}
define TOP [[ ("'") Alpha+ ] | Sigma({,.;!?})]] EndTag(w);
\end{verbatim}
  \end{framed}
\end{center}
% ! If you want apostrophe-joined elisions as single tokens, use
% ! [Alpha | "'"]+

\noindent where \verb+Sigma()+ is a function that extracts the alphabet of its argument, which in this case is
some punctuation marks given as a string denoted by curly braces.
When operated on the sentence
\emph{``If I am out of my mind, it's all right with me, thought Moses Herzog.''},
it produces output that looks like this

\begin{verbatim}
 <w>If</w> <w>I</w> <w>am</w> <w>out</w> <w>of</w> <w>my</w>
 <w>mind</w> <w>,</w> <w>it</w> <w>'s</w> <w>all</w> <w>right</w> 
 <w>with</w> <w>me</w><w>,</w> <w>thought</w> <w>Moses</w>
 <w>Herzog</w> <w>.</w>
\end{verbatim}

\noindent in normal \emph{matching mode}. The runtime operation of matching can be
controlled to only output the matched parts, or give positions and
lengths of tagged parts in \emph{locate mode}. Matches may also be extracted
via an API call to control the flow of data more precisely. The above example
operating as a more conventional tokenizer outputting one token per line and
omitting everything else can be written as

\begin{center}
  \begin{framed}
\begin{verbatim}
define TOP [[Alpha | "'"]+ | Sigma({,.;!?})]] 0:"\n";
\end{verbatim}
  \end{framed}
\end{center}

\noindent and run in \emph{extract-matches mode}.

\subsection{Tokenizing with a Dictionary}

A tokenizer consists of the input side of a morphological dictionary.
Good coverage in vocabulary and derivation can satisfactorily solve
many tokenization headaches on its own. For example, consider the plural 
possessive of the compound in

\begin{exe}
  \item The Attorney-Generals' biographies are over there.
\end{exe}

\noindent To get the tokenization of the example exactly right, a tokenization rule 
needs to understand that the hyphen is joining parts of a compound word, unlike in e.g.
\emph{Borg-McEnroe}, and that the apostrophe is indicating the possessive form,
not the end of a quotation.

A dictionary can also be augmented to recover from
formatting or digitalisation issues. For example, a text may split words
at line boundaries with hyphens, as in

\begin{exe}
\item He seemed suddenly to have been endowed with super-

  human strength
\end{exe}

\noindent In this example,  the correct tokenization is \mbox{\emph{superhuman}} rather than
\mbox{\emph{super}} and \mbox{\emph{human}}, but a dictionary would miss this possibility. However,
we can use a finite-state operation to allow the string \verb+-\n+ (hyphen
followed by a newline) to appear anywhere inside the words in the dictionary.
In regular expressions this operation is sometimes called \emph{ignoring} and in
\verb+pmatch+ is invoked with a forwards slash, like so:

\begin{center}
  \begin{framed}
\begin{verbatim}
define dict_with_linebreaks [dict]/[{-}"\n"]
\end{verbatim}
  \end{framed}
\end{center}

\noindent The \verb+\n+ is in double quotes in order to invoke parsing it as a newline
rather than as a literal ``\textbackslash n'' and \verb+dict+ is the name of a dictionary transducer. 

\subsubsection{Preserving the Parts of a Multi-word Unit}

Dictionaries are often equipped with a collection of short idioms, e.g.\@
\emph{in view of}, and other tokens which include whitespace, e.g.\@
\emph{New York}. While these are useful, it may be too early at this stage
to fix the tokenization as the longest possible match. A discriminative
tagger may not be able to make the correct choice in

\begin{exe}
\item The ball was in view of the referee.
  \label{inview}
\end{exe}

\noindent if it only sees a tokenization where \emph{in view of} is a single token.

We can extend the dictionary in a simple way to also contain the other
possible tokenizations and, in the case of a morphological dictionary,
the analyses, as follows

\begin{center}
\begin{framed}
\begin{verb}
define combined_tokens [dict].u .o. [dict | [" " dict]*]  
\end{verb}
\end{framed}
\end{center}

\noindent where \verb+dict+ is our dictionary and \verb+[dict].u+ is its input
projection. We compose it with arbitrarily many copies of itself,
interspersed with space characters. The result contains every multi-word
expression both as itself, and as a combination of other words found
in the dictionary.

In addition to bare tokens, many downstream tools use analysis cohorts, i.e.\@
the full set of possible base forms and morphological tags for the token in
question. The \verb+hfst-pmatch+ utility exposes an API that allows retrieval of the
position, length, input, output, tag and weight of each of the longest matches, 
so cohort formatters can be written. 
For example, suppose our dictionary includes the
following entries

\begin{table}[H]
\begin{center}
\begin{tabular}{| l | c  c  c |}
  \hline
  \textbf{in} & in AVP & in NN0 & in PRP \\
  \hline
  \textbf{view} & view NN1 & view VVB & view VVI \\
  \hline
  \textbf{of} & of PRF & of PRP & \\
  \hline
  \textbf{in view of} & & in view of PRP & \\
  \hline
\end{tabular}
\end{center}
\end{table}

\noindent when tokenizing \emph{in view of}. The combined dictionary will then produce the full
set of combinations which may be formatted as follows

\begin{center}
\begin{framed}
\begin{verbatim}
"<in view of>"
   "in view of" PRP
   "in" AVP "view" VVI "of" PRF
   "in" NN0 "view" VVB "of" PRF
   "in" NN0 "view" VVB "of" PRP
   "in" NN0 "view" VVI "of" PRF
   etc.
\end{verbatim}
\end{framed}
\end{center}

\subsection{Tokenization Rules as Fallback}

When no match from the dictionary or a morphological guesser is available,
\verb+pmatch+ by default
writes input to output as-is. Ideally, we would like to assign every character
in the input either to some intentional token, or discard it. 
To achieve this, we must write a rule representing
\emph{some other word} and disjunct it with the dictionary at the top level of
our tokenizer. To discard unwanted input, we must either adopt the convention
that the parts of the input that have not been
given any tag are discarded, or explicitly add a rule that rewrites single
unmatched characters to empty strings. The following abbreviated example for English
employs some knowledge about intra-word punctuation.

\begin{center}
\begin{framed}
\begin{verbatim}
define special_plurals [abbreviation | numeric_expression] {'s};
define possessive_s_ending
 OR(LC({s}) LC({se}) LC({z}) LC({ze}) LC({ce}) LC({x}) LC({xe}))
 {'} ({s});
define possessive_suff [{'s} | possessive_s_suff];
define OOVwordpart [Alpha+ (possessive_suff)] | special_plurals;
define OOVword [OOVwordpart [{-} OOVwordpart]*]::1.0;
define TOP dict | OOVword;
\end{verbatim}
\end{framed}
\end{center}

\noindent In the above example, we join possessive endings and hyphen-joined compound words at the top
level into single matches, but by either adding tags at the appropriate level
or by changing what is included at the top level it is easy to control the
tokenization. By weighting the out-of-vocabulary (OOV) \verb+OOVword+ rule in the \verb+hfst-pmatch+ expression with \verb+::1.0+, 
we ensure that equally long dictionary matches, which have zero weight, will be preferred over \verb+OOVword+ matches.

%% \subsubsection{Incorporating other Linguistic Units}

%% Many nonverbal expressions that are (usually) not covered by dictionaries,
%% eg.\@ ``7:39 PM'', ``21.05 €'' or ``December 10th, 2101''

%% time expressions? numeric quantities? money? chunking?

%% Since in \verb+pmatch+ multiple rules operate on the same input, it is possible
%% to integrate higher-level tokenization, such as grouping tokens into sentences
%% and sentences into paragraphs in the same ruleset.

\section{Morphological Tagging using {\tt hfst-finnpos}}\label{sec:morph-tagging}
% Miikka (4 p.)

In this section, we learn how to disambiguate a tokenized and morphologically analyzed
text. In addition, we learn how to train the morphological tagger {\tt hfst-finnpos}.

FinnPos \cite{silfverberg/2015} is a data driven {\it morphological
  tagging} toolkit distributed with the HFST interface. The term
morphological tagging \cite{chrupala/2008} refers to assigning one
full morphological label, including for example part-of-speech, tense,
case and number, to each word in a text. It can be contrasted with
POS tagging where the task is to infer the correct part-of-speech for
each word.

The FinnPos toolkit is based on the Conditional Random Field (CRF) framework
\cite{lafferty/2001} for data driven learning. Most work on CRF
taggers and other discriminative taggers has concentrated on POS
tagging for English, which has a very limited selection of productive
morphological phenomena. In contrast, FinnPos is especially geared
toward morphologically rich languages with large label sets, that
cause data sparsity and slow down estimation when using standard
solutions. FinnPos gives state-of-the-art results for the
morphologically rich language Finnish \cite{silfverberg/2015} both
with regard to runtime and accuracy.  In addition to morphological tagging, 
FinnPos also performs data driven lemmatization. 
Moreover, it can be combined with a morphological analyzer 
to make a data-driven morphological disambiguator. 
The capability of FinnPos to take advantage of the linguistic choices 
made by developers of morphological lexicons is the reason for including 
FinnPos in the HFST tool set.

In this section, we will focus on describing FinnPos from a
practical point of view. A more detailed description of the theoretical foundations 
as well as evaluation can be found in
\cite{silfverberg/2015}.

\subsection{FinnPos for Morphologically Rich Languages}

In part-of-speech (POS) tagging, the label sets are usually fairly small. For example,
the Penn Treebank uses only 45 distinct label types. For tagging of
morphologically complex languages, where full morphological labels are
required, vastly larger label sets are used. Label sets of around 1,000
distinct label types frequently occur. 

Large label sets create a data sparsity problem. For example, for a
second order language model and a label set of 1,000 distinct label types, an
overwhelming majority of the one billion possible (1,000$^3$) label
trigrams are never seen in a training corpus of realistic scope. Even
label unigrams may be rare as many label unigrams tyically occur only a couple 
of times in a training corpus.

Although morphological label sets can be very large, individual labels
are usually created by combining smaller sub-units from a relatively
small inventory. A typical example of such a structured morphological
label is the label {\tt Noun|Sg|Nom}, which consists of three sub
units: the main word class {\tt Noun}, the singular number {\tt Sg}
and the nominative case {\tt Nom}. FinnPos utilizes the internal
structure of complex labels by extracting features for sub-units as
well as for the entire labels \cite{silfverberg/2014}. This alleviates
the data sparsity problem because features relating to sub-units of
entire tags are used as fall-back. Additionally, sub-unit features
allow FinnPos to model grammatical generalizations such as case
congruence in isolation of the full labels.

In addition to data sparsity, large label sets cause long training
times because the complexity of standard CRF training of an $n$th
order model depends on the $(n+1)$st power of the label set size. To
speed up training, FinnPos uses an adaptive beam search and a label
guesser \cite{silfverberg/2015} during inference and estimation. These
substantially reduce run-time.

\subsection{FinnPos Tools}

The FinnPos toolkit includes three command-line tools

\begin{itemize}
\item {\tt finnpos-train} for training tagger models.
\item {\tt finnpos-label} for using models to label data.
\item {\tt finnpos-eval} for evaluation against a gold standard.
\end{itemize}

Additionally, FinnPos provides a Python script {\tt
  finnpos-ratna-feat.py} used for feature extraction. The script is
named after Adwait Ratnaparkhi because FinnPos uses a modified version
of the feature set introduced by Ratnaparkhi in
\cite{ratnaparkhi/1996}.

% FinnPos can utilize HFST morphological analyzers and other
% morphological analyzers. 
The integration of a morphological analyzer
is accomplished by piping the output of the analyzer to FinnPos. 
FinnPos uses the '\verb@|@' sign to separate sub-units
of structured tags, e.g. {\tt Noun|Sg|Nom}, so tags emitted 
by a particular morphological lexicon may require minor editing. 
In HFST, morphological lexicons can be edited with the {\tt hfst-xfst} utility.

\subsection{Data Format and Feature Extraction}

\begin{figure}
\begin{framed}
\begin{verbatim}
The    WORD=The LC_WORD=the       the   Det                _
dog    WORD=dog LC_WORD=dog       dog   Noun|Sg|Nom        _
barks  WORD=barks LC_WORD=barks   bark  Verb|Ind|Pres|3sg  _
.      WORD=. LC_WORD=.           .     .                  _

Their  WORD=Their LC_WORD=their   they  Pron|Pl|Gen        _
cat    WORD=cat LC_WORD=cat       cat   Noun|Sg|Nom        _
meows  WORD=meows LC_WORD=meows   meow  Verb|Ind|Pres|3sg  _
.      WORD=. LC_WORD=.           .     .                  _
\end{verbatim}
\end{framed}
\caption{Small example of data format.}
\end{figure}

The utilities {\tt finnpos-train} and {\tt finnpos-label} read and write input
sentences in a five column tab-separated format where each row
corresponds to one text token and the columns denote

\begin{enumerate}
  \item  Word form (e.g. ``Dogs'').
  \item  Features separated by spaces (e.g. \verb|WORD=dogs PREV_WORD=the|).
  \item  lemma (e.g. ``dog'').
  \item  Label (e.g. \verb|NNS|).
  \item  Annotations (arbitrary text not containing tabulators).
\end{enumerate}

When using a file as training or development file for {\tt
  finnpos-train}, the lemma and label fields have to contain exactly
one value each. When using {\tt finnpos-label} for tagging data, the
label field can either be empty or contain a number of label
candidates separated by spaces. 

The default feature extraction script {\tt finnpos-ratna-feats.py}
extracts the following features for frequent words:

\begin{enumerate}
\item Word form.
\item Previous word form.
\item Next word form.
\item Previous two words.
\item Next two words.
\end{enumerate}

\noindent For rare words, the script also extracts orthographic features:

\begin{enumerate}
\item Suffixes and prefixes up to length 10.
\item Capitalization.
\item Whether the word includes digits or dashes.
\end{enumerate}

\noindent Users may add their own features such as the output of a
morphological analyzer before calling {\tt finnpos-ratna-feats.py} or
write their own feature extraction script.

The fifth field in the data format is reserved for annotations. These
are passed unchanged through the tool {\tt finnpos-label}. The
annotation field can be used to transport word-specific information
through the tagger, e.g., lemmatization or named entity labels.

\subsection{Training and Using a Model}

FinnPos uses an averaged perceptron algorithm with early stopping for
estimation of model parameters. The error-driven perceptron training
algorithm iterates through the training corpus one sentence at a time,
labels the sentences and adjusts model weights when erroneous labels
are detected. Usually the Viterbi algorithm \cite{collins/2002} is
used for labeling. This, however, is too slow in practice when dealing
with large label sets.

Instead of the Viterbi algorithm, FinnPos uses beam search with
an adaptive beam width \cite{pal/2006}. Additionally FinnPos uses a generative
label guesser modeled after the OOV word model used in
\cite{brants/2000} to restrict label candidates during
training. Because of inexact inference during the training phase,
FinnPos additionally uses violation fixing \cite{huang/2012}.

Users can train their own models using the utility {\tt
  finnpos-train}. The training process is regulated using a
configuation file, see Figure~\ref{fig:config-file}. The
configuration file is used for setting the hyper parameters of the beam
search and label guesser as well as the stopping conditions for the
perceptron algorithm, see Figure~\ref{fig:config-fields}.

\begin{figure}
\begin{framed}
\begin{verbatim}
# Config file for FinnTreeBank tagger.

guess_mass=0.999
beam_mass=0.999
max_train_passes=3
max_lemmatizer_passes=7
\end{verbatim}
\end{framed}
\caption{Example configuration file.}\label{fig:config-file}
\end{figure}

\begin{figure}
\begin{tabular}{ll}
{\tt suffix\_length} & The maximal suffix length used in feature extraction during\\
                     & lemmatization.\\
{\tt degree} & The degree of structured features used by the tagger. \\
{\tt max\_train\_passes} & The maximal number of training passes during estimation of tagger\\
                         & parameters.\\
{\tt max\_lemmatizer\_passes} & The maximal number of training passes during estimation of\\
                              & lemmatizer parameters.\\
{\tt max\_useless\_passes} & The maximal number of passes over the training data\\
                           & that do not improve the tagging accuracy for the development data.\\
{\tt guess\_mass} & A generative label guesser is used to prune the label candidates\\
                  & considered for each word during training, where {\tt guess\_mass}\\
                  & is a float in range (0\ldots1) which determines the mass of the candidates\\
                  &  preserved by the guesser for each word.\\
{\tt beam\_mass} & FinnPos uses an adaptive beam to prune search histories during\\
                 & beam search. This parameter determines the probability mass of the\\
                 & beam.
\end{tabular}
\caption{Description of configuration file fields.}\label{fig:config-fields}
\end{figure}

\subsection{FinnPos and Morphological Analyzers}

FinnPos benefits from a morphological analyzer for morphological disambiguation. 
The analyzer can be used in two ways: to provide label candidates for words 
and as a generator of features. For words not recognized by the analyzer, 
FinnPos will use a data-driven suffix-based guesser to generate label candidates.
In addition to the morpological label, FinnPos also uses the
morphological analyzer for determining the lemma of a given word. For
words not recognized by the analyzer, a data-driven lemmatizer is used
instead. The data-driven components are learned from the training corpora, which means
that the FinnPos tagger could be used without a morphological analyzer, 
but a lexicon with reasonable coverage improves the tagging performance.

\section{Semantic Tagging using {\tt hfst-pmatch}}\label{sec:sem-tagging}
% Sam (4 p.)

In this section, we outline a scheme for extracting semantic frames from text
using hand-written rules. The rules and approach has been demonstrated in~\cite{hardwick/2015}. 
The current paper is more extensive and includes an evaluation of the rule set. While it does not currently 
represent a system for extracting a large number of different frames, 
the \verb+hfst-pmatch+ tool has been extensively tested in a full-fledged 
named-entity recognizer for Swedish \cite{Kokkinakis-Dimitrios2014-3}. 
Our motivation here is to present additional capabilities of 
\verb+hfst-pmatch+ as a natural language processing system for extracting 
factoids from textual data to be used in text and data mining.

\subsection{Introduction}

A semantic frame \cite{semantic-frame} is a description of a \emph{type} of event, relation or entity
and related participants. For example, in FrameNet, a database of semantic frames,
the description of an \verb+Entity+ in terms of physical space occupied by it is
an instance of the semantic frame \verb+Size+. The frame is evoked by
a lexical unit (LU), also known as a frame evoking element (FEE), which is a
word, in this case an adjective,
such as \emph{big} or \emph{tiny}, descriptive of the size of the \verb+Entity+.
Apart from an \verb+Entity+, which is a core or compulsory element, the
frame may identify a \verb+Degree+ to which the \verb+Entity+ deviates
from the norm, e.g., \emph{a \textbf{really} big dog}, and a \verb+Standard+ with
which it is compared, e.g., \emph{tall \textbf{for a jockey}}.

\begin{table}[h]
\begin{center}
  \begin{tabular}{ l | l}
\hline
Lexical Unit (LU) & Adjective describing magnitude (large, tiny, ...) \\
Entity (E) & That which is being described (house, debt, ...) \\
Degree (D), optional & Intensity or extent of description (really, quite, ...) \\
Standard (S), optional & A point of comparison (for a jockey, ...) \\
\hline
    \end{tabular}
    \caption{The semantic frame \emph{Size}.}
\end{center}
\end{table}

For example:

\begin{table}[h]
\begin{center}
\begin{math}
\Big[_{\text{Size}}\Big[_{\text{E}}\text{He} \Big]
  \text{is} \Big[_{\text{D}} \text{quite} \Big] \Big[_{\text{LU}}\text{tall} \Big]
  \Big[_{\text{S}} \text{for a jockey} \Big] \Big]
\end{math}
\end{center}
\caption{A tagged example of \emph{Size}}
\end{table}

\subsection{A Rule}

A simple and common syntactic realization of the \verb+Size+ frame is a single
noun phrase containing one of the LUs, such as
\emph{the big brown dog that ran away}. Here we would like to identify \emph{big} as \verb+LU+,
\emph{brown dog} as \verb+Entity+ and the combination as \verb+Size+.
Our first rule for identifying this type of construction might be

\begin{table}[h]
\begin{center}
  \small
  \begin{framed}
\begin{verbatim}
define LU {small} | {large} | {big} EndTag(LU);
define Size1 LU (Adjective) [Noun EndTag(Entity)].t(Entity);
define TOP Size1 EndTag(Size);  
\end{verbatim}
\end{framed}
\normalsize
\caption{A simplified first rule}
\end{center}
\end{table}

\noindent This rule set has been simplified for brevity -- it only has a few of the
permitted LUs, and word boundary issues have not been addressed.
The \verb+[].t()+ syntax in the definition of \verb+Size1+ is a tag delimiter
controlling the area tagged as \verb+Entity+. The extra \verb+Adjective+ is
optional, which is conveyed by the surrounding parentheses.

\sloppy We can verify that our rules extract instances of our intended pattern by compiling
them with \verb+hfst-pmatch2fst+ and running the compiled result with
\verb+hfst-pmatch --extract-tags+. In the following we have
inputted the text of the King James Bible from Project
Gutenberg\footnote{\url{http://gutenberg.org}} and allowed some extra characters on both
sides for a concordance-like effect

%\begin{table}[h]
\hfill \break
  \small
\begin{center}
  \begin{framed}
\begin{verbatim}
...
there lay a <Size><LU>small</LU> round <Entity>thing</Entity></Size>
...
there was a <Size><LU>great</LU> <Entity>cry</Entity></Size> in Egypt
...
saw that <Size><LU>great</LU> <Entity>work</Entity></Size> which
...
\end{verbatim}
\end{framed}
\end{center}
\normalsize
%\caption{Fragments of tagged running text}
%  \label{bibletext}
%\end{table}

A natural next step is to add optional non-core elements, such as an adverb
preceding the LU being tagged as \verb+Degree+ and a noun phrase beginning with
\emph{for a} following it as \verb+Standard+.

\begin{table}[h]
\begin{center}
  \small
  \begin{framed}
\begin{verbatim}
define Size1 [Adverb].t(Degree) LU (Adjective) [Noun].t(Entity) 
             [{for a} NP].t(Standard);
\end{verbatim}
\end{framed}
\end{center}
\normalsize
\caption{Extending the rule with optional elements}
\end{table}

\noindent and here are some examples this rule finds in the British National
Corpus~\cite{bnc}

%\begin{table}[h]
\begin{center}
  \small
  \begin{framed}
\begin{verbatim}
...
presence of an <Size><Degree>arbitrarily</Degree>
  <LU>small</LU> <Entity>amount</Entity></Size> of dust
...
one <Size><LU>small</LU> <Entity>step</Entity>
  <Standard>for a man</Standard> </Size>
...
\end{verbatim}
  \end{framed}
\end{center}
  \normalsize
%  \caption{Tagged text with optional elements}
%  \label{bnctext}
%  \end{table}

\noindent We can see that in \emph{small amount of dust}, we might want to
tag not just the immediate noun as \verb+Entity+ but the entire noun phrase
which could be implemented up to a context-free definition of a noun phrase,
and in \emph{one small step for a man} a common indirect use of the \verb+Standard+
construction. As well as correct matches, such as \emph{small round thing} in the biblical
example, we have metaphorical meanings of \verb+Size+, such as \emph{great cry}.
This may or may not be desired -- perhaps we wish to do further processing to
identify the target domains of such metaphors, or perhaps we wish to be able
to annotate physical size and physical size only.

\subsection{Incorporating Semantic Information}

Size is a very metaphorical concept, and syntactic rules as above will produce a large amount of matches that relate to such uses, e.g., \emph{a great cry} or \emph{a big deal}. If we wish to refine our rules to detect such uses, there are a few avenues to explore. First of all, some LUs are much more metaphorical than others. A \emph{great man} is almost certainly a metaphorical use, whereas a \emph{tall man} is almost certainly concrete. Accuracy may be improved by requiring \emph{great} to be used together with common nouns meaning several individuals like a \emph{great crowd}. In addition, there are semantic classifications of words, such as WordNet~\cite{wordnet}. We may compile the set of hyponyms of \emph{physical entity} and require them to appear as the nouns in our rules as shown in Table~\ref{physical}.

\begin{table}[h]
\begin{center}
\small
\begin{framed}
\begin{verbatim}
define phys_entity  @txt"phys_entity.txt";
\end{verbatim}
\end{framed}
\end{center}
\normalsize
\caption{Reading an external linguistic resource}
  \label{physical}
\end{table}

\subsection{Incorporating Part-of-speech Information}

We have so far used named rules for matching word classes like \verb+Noun+,
without specifying how they are identified. Also our collection of LUs might need
some closer attention -- for example \emph{little} could be an adverb.
Considering that in writing our
rules, we are effectively doing shallow syntactic parsing, even a very simple
way to identify parts of speech may suffice, e.g. a morphological dictionary.
For example, a finite-state transducer representing English morphology may be
used to define the class of common nouns as in Table~\ref{dictrules}.
If we have the use of a part-of-speech tagger, we may write our rules to act
on its output, as in Table~\ref{posrules} where \verb+W+ refers to some word delimiter.

\begin{table}[h]
\begin{center}
\small
  \begin{framed}
\begin{verbatim}
! The lexicon we want to read
define English @bin"english.hfst";
! We compose it with a noun filter and extract the input side
define Noun  [ English .o. [?+ "<NN1>" | "<NN2>"] ].u;
! (NN1 is singular, NN2 plural)
\end{verbatim}
\end{framed}
\end{center}
  \normalsize
  \caption{Using a dictionary to extract words of a given word-class}
  \label{dictrules}
  \end{table}

\begin{table}[h]
\begin{center}
  \small
  \begin{framed}
\begin{verbatim}
define Noun LC(W) Wordchar+ ["<NN1>"|"<NN2>"] RC(W);
\end{verbatim}
\end{framed}
\end{center}
  \normalsize
  \caption{Using tags in pre-tagged text}
  \label{posrules}
  \end{table}

\subsection{Increasing Coverage}
Having considered for each rule where \verb+Degree+ and \verb+Standard+ may occur, coverage may be evaluated by also finding those cases where a LU is used as an adjective but does not match the current rules, e.g.

\begin{center}
  \small
  \begin{framed}
\begin{verbatim}
define TOP Size1 | Size2 | [LU].t(NonmatchingLU);
\end{verbatim}
  \end{framed}
\end{center}
\normalsize

The valid match is always the longest possible one, so \verb+NonmatchingLU+ will be the tag only if no subsuming \verb+SizeN+ rule applies.
For example in

\begin{center}
\small
\begin{framed}
\begin{verbatim}
the moving human body is <NonmatchingLU>large</NonmatchingLU>,
obtrusive and highly visible
\end{verbatim}
\end{framed}
\end{center}
\normalsize

\noindent we see another realization of the \verb+Size+ frame: the \verb+Entity+ is followed by a
copula, and the \verb+LU+ appears to the right. We can write a new rule
\verb+Size2+ to capture this, adding positions for non-core elements either by
linguistic reasoning or by searching the corpus.

\section{Evaluation}

FrameNet has published a tagged extract of the American National
Corpus~\cite{anc}~\footnote{The FrameNet-annotated texts are at\\\url{https://framenet.icsi.berkeley.edu/fndrupal/index.php?q=fulltextIndex}},
consisting of 24 texts. Of these, one uses the \verb+Size+ frame 35 times, but the remainder use it only an additional 6 times
for a total of 41 times. This is too thin a selection, and suggestive of some inconsistency in the use of this frame vs.\@
some alternative ones such as \verb+Dimension+, and various metaphorical sub-cases of that frame.
Evaluating the extraction of the \verb+Size+ frame on the basis of this minute corpus was unfeasible, 
but we used it as a reference when developing our own training and test set.

To develop our rule set, we took 200 sentences of the British National
Corpus containing, as a token, one of the \verb+LU+s, and tagged them by hand.
We considered a LU to be any inflected form of a word of the synonyms to \emph{size} given by WordNet
including metaphorical meanings of size.
The sentences had POS tags from the original material, but punctuation
and information about multi-word units was removed before developing
the rule set. This corresponds to running surface text through a POS tagger which does not recognize multi-word expressions before
running the frame extractor.

We had one person spend a working day developing rules based on our set of training samples, iterating a process
of spotting the difference between the hand-tagged samples and the
tagging produced by our rules, and modifying the rule set. This  resulted
in two top-level rules, one corresponding to cases where the \verb+LU+ precedes
the \verb+Entity+, and one to cases where it follows as these were the only
compulsory elements in the frame. Overall, the rule set was 46 lines long, excluding comments and whitespace.

To get an idea of the quality of the rules, we also hand-tagged another 100 sentences from the same corpus. 
These do not necessarily contain the \verb+Size+ frame to test that the rules do not over-generate.
Of these sentences, 81 were tagged completely correctly by the rule set. Results by \verb+LU+ are in
Table~\ref{luperf}.

\begin{table}[h]
  \centering
  \begin{tabular}{l | l}
    \hline
    Number of sentences & 100 \\
    Number of LUs & 113 \\
    Number of LUs corresponding to a \verb+Size+ frame & 56 \\ %non-sizes = 57
    Number thereof matched by the rules & 50 \\
    Total number of matches made by the rules & 54 \\
    \hline
    Coverage & 89\% \\
    Accuracy & 93\% \\
    \hline
  \end{tabular}
  \caption{LU-level semantic tagging performance on the 100 sentence test set}
  \label{luperf}
\end{table}

In Table~\ref{luperf}, a match in the test material is considered correct if the relevant \verb+LU+
is correctly identified. We explore some further details regarding the quality of both
correct and incorrect test matches in Table~\ref{framequality}.

\begin{table}[h]
  \centering
  \begin{tabular}{ l | l }
    \hline
    Matches where wrong \verb+Entity+ was tagged & 4 (8\%) \\
    Matches where \verb+Entity+ was partially wrongly tagged & 8 (16\%) \\
    Matches where \verb+Degree+ was incorrectly tagged & 2 (33\% of hand-tagged \verb+Degree+s) \\
    Incorrect tagging due to insufficient rule sophistication & 9 (53\% of mistakes) \\
    Incorrect tagging due to mistakes in POS tagging & 5 (29\% of mistakes) \\
    Incorrect tagging due to lacking multi-word unit information & 2 (12\%) \\
    Incorrect tagging due to lacking punctuation information & 1 (6\%) \\
    \hline
  \end{tabular}
  \caption{Quality of matches made by the rules in the test samples}
  \label{framequality}
\end{table}

We note that the test tagging was not independent of us but no other tagging existed and that
the overall amount of both training and test material is rather small. We do not think this is a conclusive result,
but it is an indication of the semantic tagger that could be developed in a relatively small amount of time with this approach.

\section{Discussion}
% Miikka & Krister (3 p.)
In this section, we contrast HFST with some other semantic frameworks for recognizing semantic frames, 
i.e. Shalmaneser \cite{Erk2006}, LTH \cite{Johansson2007} and SEMAFOR \cite{Das2014}.

Shalmanser treats semantic frame extraction  as a pipeline 
of syntactic parsing, frame identification, semantic argument identification and semantic role labeling.
Syntactic parsing uses an external toolkit. 
% - Semantic frame identification is equated with finding predicates and
%   annotating them for semantic class (e.g. the Giving predicate).
% - Given predicates and their semantic classes, the semantic role
%  labeling component identifies the arguments of each predicate
%  (e.g. Subject, Dative, Object) and labels them with appropriate
%  semantic roles (e.g. Agent, Recipient, Theme).
Note that frame identification precedes role labeling, i.e. they are not done in parallel.
However, Erk and Pado \cite{Erk2006} claim that this would give very small gains in
accuracy while incurring huge CPU cost. 
% They refer to some statistical NLP papers that tried to do this.
Shalmaneser can be trained for any semantic annotation scheme
provided appropriate training data exists.
Users can replace some components of the system with customized
components.
Full scale models for English and German are available.
% (e.g. the machine learning component can be changed).
% The description of the evaluation in the paper is a bit unclear.
Evaluation was done on manually annotated data. FrameNet 1.2 for English and
the SALSA corpus for German. 
%  I guess, they evaluated on all semantic
%  frames. Both corpora were split randomly into a 90\% training and 10\%
%  test set. Note that these are not the data sets used by the other two
%  systems (LTH and SEMAFOR).
%In Shalmaneser, frame identification is seen as a sequence labeling task where each
%word is annotated according to its semantic class if the word is a
%predicate. 
% Evaluation is w.r.t. label accuracy (as far as I understood correctly).
%The frame identification results were 0.932 for English (vs. 0.888 using a baseline 
%of most common semantic class) and 0.790 for German (vs. 0.751 baseline).
% Semantic role labeling is seen as a chunking task, where the system
% first identifies arguments such as "The violins" and then labels
% them with argument labels, e.g. Phenomenon. 
Evaluation is w.r.t. to the F1-score on unlabeled argument chunks and labeling accuracy for
argument labels. The F1-score for argument chunks was 0.751 for English and 0.6 for
German. Argument label accuracy was 0.784 for English and 0.673 for
German.
% - I wasn't able to download Shalmaneser.
% - License restricts use to research only (as far as I understood correctly).


% LTH is a system for shallow semantic parsing. 
LTH also treats semantic frame extraction as a pipeline of syntactic parsing,
frame identification, semantic argument identification and semantic role labeling.
In contrast to many other systems, 
LTH uses a dependency syntactic parser instead of a constituent parser.
%- In the input filtering step (2), some auxiliary verbs, prepositions
%  and similar words are filtered out using rules because they have an
%  adverse effect on frame identification.
Frame identification is accomplished using a classifier based on
input words and dependency structure.
To aid argument identification, the FrameNet lexical database was
extended with WordNet data. A classifier was trained to identify
words that were likely to belong to a given semantic frame.
Evaluation was with regard to F1-score for frames and frame elements.
%  (not exactly sure what this means). 
As training data, FrameNet 1.3 was used and, as test data, three manually 
annotated segments from the American National Corpus. 
The data sets come from the SemEval 2007
joint task on frame semantic structure extraction.
The F1-score for English on the test data was 0.621.
%- BSD software license.
%- Distributed as a jar-file.
%- They don't distribute models. You're expected to train your own.

The basic architecture of SEMAFOR is similar to Shalmaneser and LTH. 
The frame parsing task is divided into two sub-tasks: predicate identification and argument identification.
SEMAFOR features a latent-variable model, semi-supervised extension of the predicate lexicon and
joint identification of the entire argument set of a predicate using linear programming.
This allows for integration of linguistic constraints on the argument sets in a principled way.
A model for English is available. 
The evaluation and data was the same as for LTH. The F1-score on English is 0.645.
% - SEMAFOR seems to be the current state of the art.
% - Distributed as JAR-file. Also depends on the MST parser.
% - Licensed under GPL3

% Sanoisin että varsinkin SEMAFOR näyttää olevan aika pitkälle kehitely systeemi. 
% Kuitenkin piakkoin kymmenen vuoden kehitystyö on johtanut melko laihoihin parannuksiin aiempiin systeemeihin verrattuna. 
% f-score on noin 0.65 kun tehtävänä on löytää semanttiset kehykset ja niiden nimetyt argumentit. 
% Tosin ilmeisesti eri annotoijatkin saavat melko erilaisia tuloksia tässä tehtävässä eli ehkä parempaa tulosta on vaikea saada.

% Luulisin että meille olisi eduksi jos voisimme sanoa jotain siitä kuinka hyvin systeemi toimii SemEval 2007 -datalla, 
% koska sitä näemmä käytetään paljon. Tämä ei tietenkään ole mahdollista vielä SFCM-paperissa...

% Jokainen näistä kolmesta systeemistä ratkaisee ongelman käyttämällä putkea, 
% jossa ensin identifioidaan semanttisen kehyksen predikaatti ja sitten sen argumentit. 
% Ehkä pmatch voi identifioida molemmat samalla kertaa? 
% Minusta vaikuttaa melko selvältä että pitäisi olla etua siitä että kehykset ja argumentit löydetään samalla kertaa.

% SEMAFOR-systeemiä lukuun ottamatta mikään noista systeemeistä ei mallinna predikaatin koko argumenttijoukkoa kerralla. 
% Ne vain etsivät yksittäisiä argumenttichunkkeja. Me taidamme mallintaa kokonaisia argumenttijoukkoa?

% Alkuperäisen FrameNetin leksikko on ilmeisesti liian pieni. 
% Jotta olisimme vakavasti otettavia, meillä on ehkä oltava jonkinlainen tapa laajentaa leksikkoa esim. käyttäen WordNetiä. 

In contrast, HFST treats semantic frame extraction as a pipeline in only two stages: morphological tagging
and semantic labeling, i.e. frame identification, semantic argument identification and semantic role labeling are done in parallel.
The fact that HFST recognizes the whole frame in one step, means that HFST has access to the whole frame element configuration
when making the decision to commit to the frame and the argument labels. In addition, HFST can take linguistic constraints
into consideration both in the morphological and the frame and role labeling tasks. This contributes to the high coverage and accuracy
in the evaluation which no doubt is still much too limited. When the whole semantic frame and all its argument roles are considered
at the same time, HFST removes part of the need for syntactic processing as an intermediate step, but nothing prevents a user from
replacing or enriching the morphological tagging with information from a syntactic parser.
Future work is a large-scale evaluation of HFST for semantic frame and role labeling of a semantically rich language like Finnish
where we will draw on the availability of FinnWordNet \cite{Linden2010fiwn} to extend the lexical unit coverage.

\section{Conclusion}\label{sec:discussion}
% Krister (1 p.)
In this paper, we have outlined the steps involved when using HFST--Helsinki Finite-State Technology
for recognizing semantic frames in context. A small-scale evaluation indicates that the setup is capable of
highly accurate semantic information labeling.

\bibliographystyle{splncs03}
\bibliography{sfcm-2015}

\end{document}
% vim: set spell:
