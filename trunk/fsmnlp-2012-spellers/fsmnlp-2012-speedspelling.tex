\documentclass[11pt]{article}

\usepackage{acl2012}

\usepackage{times}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{url}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{ifpdf}

\ifpdf
\pdfinfo{}
\fi

\title{Effect~of~Language~and~Error~Models on Efficiency~of~Finite-State
Spell-Checking~and~Correction}

\author{
Tommi A Pirinen\\
University of Helsinki\\
Department of Modern Languages\\
FI-00014 University of Helsinki, PO box 24\\
{\tt tommi.pirinen@helsinki.fi} \\\And
Sam Hardwick\\
University of Helsinki\\
Department of Modern Languages\\
FI-00014 University of Helsinki, PO box 24\\
{\tt sam.hardwick@helsinki.fi} \\
}

\date{\today (draft)}

\begin{document}

\maketitle
\begin{abstract}
In this paper we inspect the effects of different finite-state language
and error models to speed of finite-state spell-checking. We evaluate the
speed and memory consumption of full-scale real-world finite-state spell checkers
for three languages covering the broadest available spectrum of morphological
complexity; English, Finnish and Greenlandic. We evaluate the effects of
different finite-state error models and optimisations against contemporary
software-driven spell-checkers with same or equivalent spell-checking features.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

In most applications of spell-checking, efficiency is the key factor for
selecting or discarding spell-checking solutions. In case of finite-state
spell-checking it is well-known and well-researched, that finite-state language
models can efficiently encode dictionaries of natural languages
\cite{beesley/2003}, even for languages with rich and complex morphological
systems, such as polysynthetic languages. The efficiency of finite-state
approaches to spell-checking, however, has often been seen as a problem, and
therefore most of the contemporary spell-checking system are still based on
programmatic solutions (e.g. hunspell\footnote{\url{http://hunspell.sf.net}},
and its *spell relatives), or at most specialised algorithms for implementing
fuzzy traversal of the finite-state dictionaries
\cite{oflazer/1996,hulden/2009}. There has also been few implementations of
using fully finite-state implementations for both the error-detection and
corrections \cite{schulz/2002,pirinen/2010/lrec}. In this paper we further evaluate
the use of finite-state dictionaries with two-tape finite-state automatons for
mechanism to correct misspellings, and how to optimise the finite-state error
models. 

To evaluate general usability and efficiency of finite-state spell-checking we
test the system with three languages of typologically different morphological
features and different reference implementations for contemporary
spell-checking applications: We use English as a sample for morphologically
poor language with basically plain word-list approach to spell-checking; for
reference implementation we use the hunspell's en-US
dictionary\footnote{\url{}} and for finite-state version we use weighted
word-list from \cite{norvig/2010}. The second language we test is Finnish, a
morphologically more rich language which is still agglutinative. Finnish is
among the morphologically simpler languages that have no working implementation
under hunspell, and for reference implementation we use
voikko\footnote{\url{http://voikko.sf.net}}, with LAG-based dictionary. Our
third test language is Greenlandic, a polysynthetic language which has, to our
knowledge, always been implemented as finite-state systems for spell-checking
utilities. There are no free software for reference implementation apart from
our solution, as far as we know.

The baseline feature-set and the efficiency of spell-checking we are targeting
is defined by the currently de facto standard spelling suite in open source
systems, hunspell. As both Finnish and Greenlandic have not been successfully
implemented in hunspell formalism, we mainly use them to evaluate how complexity
of language model effects the efficiency of finite-state spell-checking. For
full-scale survey on the state-of the art non-finite-state spell-checking we
refer to \cite{mitton/1996}.

The efficiency results are contrasted to previous research on finite-state
spell-checking in~\cite{hassan/2008} and the theoretical results on
finite-state error-models in~\cite{mitankin/2005} with the additions of
morphological complex languages with actual cyclic dictionary automata and more
complex structure than those of English and Arabic. We note in particular that
previous approaches have neglected to simultaneously constrain the error
model and the dictionary with each other in on-line composition, which
affords a significant speed benefit.

The rest of the paper is organised as follows. In Section~\ref{sec:methods} we
introduce methods used by current non-finite-state spell-checkers and
previously used finite-state methods for spell-checking and correction and
propose some possible speed optimisations for the error models. In
Section~\ref{sec:materials} we present the language models, error models, the
testing corpora and the earlier work. In Section~\ref{sec:evaluation} we
present the comparisons of speed and quality with combinations of different
language and error models and corpora for spell-checking. In
Section~\ref{sec:conclusions} we summarise our findings and results for use
of finite-state spell-checking.


\section{Methods}
\label{sec:methods}

A finite-state spell-checker is typically composed of at least two finite-state
automata; one for dictionary of the language, or the \emph{language model},
which contains valid strings of the language, and one automaton to map misspelt
words into correct strings, or the \emph{error model}. Both the language models
and the error models are usually weighted as finite-state automata, in which
case it is probability of word being correctly spelled in the language model
and the probability of specific misspellings that are assigned by the automata.
We evaluate here the effect of both the language model automaton's structure
and complexity, and the error models structure and complexity to the efficiency
of the finite-state spelling. 

\subsection{Language Models}
\label{subsec:language-models}

The most basic language model for spell-checking dictionary is a list of
correctly spelled word-forms. One of the easiest way to create such 
spell-checker is collecting the word-forms from reasonably large corpus of
mostly correctly spelt texts; additionally we can count the frequency of words
and use that as likelihood $P=\frac{c(\mathrm{wordform})}{\mathrm{Corpus size}}$
For morphologically poor languages such as English, this is often sufficient
approach\cite{norvig/2010}, and we use it to create dictionary for our English
spell-checking dictionary as well.

For morphologically slightly richer languages like Finnish, for which the
word-list approach is likely to miss much greater amount of words \cite{}, one
of the commonest approaches is to use right-linear grammars, possibly combined
with finite-state rule languages to implement morphophonological alterations
\cite{koskenniemi/1983,beesley/2003}. This approach also applies to the newest
available free open source and full fledged finite-state Finnish morphological
dictionary we found \cite{pirinen/2011/nodalida}. This language model features
productive derivations, compounding and rudimentary probabilistic models from.
The reference non-finite state language model for Finnish we found from
currently used spell-checker is implemented in left-associative grammar
formalism, a potentially slightly less efficient system with more expressive
power and similar feature set as finite-state formulation in terms of
linguistic coverage.

For polysynthetic languages it will be obvious that coverage of any
word-list-based approach will be low, furthermore most simple extensions to it
such as affix stripping of hunspell are not enough for describing word-forms of
language. To our knowledge, the only approaches that have been in wide use for
spell-checking and morphological analysis of Greenlandic have been based on
traditional finite-state solutions like the Xerox formalisms as with Finnish
finite-state dictionaries.

\subsection{Error Models}
\label{subsec:error-models}

The ubiquitous formula for modeling typing errors since the beginning of the
spelling correction by computer has been the edit-distance algorithm
sometimes attributed to 
Levenshtein\cite{levenshtein/1966} and/or Damerau\cite{damerau/1964}. What the
algorithm does is it maps four most typical slips of fingers on keyboard to
events in the fuzzy matching of the misspelt word-forms to correct ones, that
is, deletion of character (i.e. not pressing a key), addition of a character
(i.e. pressing extra key accidentally), changing a character (i.e. pressing
wrong key) and swapping adjacent characters (i.e. pressing two keys in wrong
order). When modeling edit distance as finite-state automaton, a relatively
simple two-tape automaton is enough to implement the algorithm 
\cite{hassan/2008}. 
Basically the automaton will consist one arc for each type of error, 
additionally one state for each swapping of character type of error is needed to
keep the character pair to be swapped in memory. This means that the trivial
NFA implementing the algorithm is of space complexity $O(V, E) = 
|\Sigma|^2 |V| + |\Sigma|^2 |E|$, where $\Sigma$ is the alphabet of language,
$V$ is the set vertices in automaton and $E$ is the set of edges in automaton.
This edit distance formulation is roughly feature equivalent to hunspell's
\texttt{TRY} mechanism.

To further finetune this finite-state formulation of edit distance algorithm, it
is possible to attach a probability to each of the error events as a weight in
weighted finite-state automaton, which corresponds the likelihood of error or
confusion factor. This can be used to implement features like keyboard adjacency
or OCR confusion factor to the error correction model. This will not modify
the structure of the finite-state error models or the search space, but 
introduction of non-homogenous weights to resulting finite-state network
may have an effect on search time. This addition is equivalent to hunspell's
\texttt{KEY} mechanism.

For typical spelling-checkers it is also common to provide separate list of
very frequent misspellings as a confusion set. The finite-state formulation
of such confusion set is very trivial, for each word-form confusion we add
one path to the error model mapping the common misspelling to the correct
form. This is equivalent to hunspell's \texttt{} mechanism.

For English language spelling correction there is also additional form of
error model to deal with competence related misspellings, as opposed to these
other models that mainly deal with mistypings, implemented in form of phonemic
folding and unfolding. This type of error is very specific to certain type of
English texts and is not dealt with in scope of this research. This is what is
the \texttt{PHON} part of the hunspell's correction mechanism.

Beyond fine-tuning the error models to reimplement hunspell's feature set, we
use propose different variations of this edit-distance scheme to optimise the
speed of error correction with little or no negative effect to the quality of
correction suggestions. The factors that make up the time of the finite-state
spelling correction algorithm are the size of the search space, i.e. the
complexity of resulting network when the error model is applied to the misspelt
string and intersected with the dictionary\footnote{correspondingly for
non-finite-state solution, the search space is simply amount of the possible
strings given the error corrections made in the algorithm, for finite-state
system the amount of generated strings with cyclic language and error models is
infinite so complexity calculation is theoretically slightly more complex,
however for basic edit distance implementations used in this article the search
space complexities are always the same and amount of suggestions generated
finite}. As an example of complexity calculation, applying $N$ edit distance
errors to string $s$ will theoretically generate a search space of a size in
$O(...) = FIXME PLZ$, \cite{mitankin/2005} of course the real search
application in both fuzzy string matching and the finite-state implementation
will use the dictionary to branch-and-bound limit the search space into
substrings that would end up in legal word-forms so the actual search spaces
will depend on structure of the dictionary and therefore will not be trivially
predictable anymore .

To optimise the application of edit distance by limiting the search space
bearing in mind the structure of dictionary, many traditional spell checkers
will not attempt to correct the very first letter of the word-form. We estimate
this to be reasonable in finite-state systems as well, since it would typically
appear that finite-state automata for dictionaries of natural languages have
the most dense arc structure in the initial state of the automaton; excluding
that from the application of errors will then give greatest improvements to
search space minimising. On the error-model side this optimisation has been
justified by findings where only NNN \% of spelling-errors happen in the first
character of the word\cite{Yannakoudakis/1983}. To further accommodate this
optimisation to the structure of the morphologically complex languages we treat
the compound word boundaries like the ultimate beginning of the word by adding
special word boundary character to the dictionary on word boundaries, and
applying the optimised edit-distance models to only characters one or more
beyond this boundary.

Second form of optimisation that is used by many traditional spell-checking
systems as well, is to apply the lower order edit distances separately before
trying higher order ones. This is based on the assumption that vast majority
of spelling errors will be of lower order, as is given in the original
description of the edit distance for spell-checking, 80 \% of the spelling
errors can be \cite{Pollock/1984}.

Third form of the optimisation that we test is an attempt to decrease the
number of redundant corrections in error models of higher order edit distances
than one. This means that things like  adding and deleting the
same character in successive moves will not be performed. This makes the error
model more complicated but reduces the search space, and does not affect the
quality of results at all.

Further optimisations like disallowing disjoint errors in higher order error
models and so not we may test if we have time.

\section{Material}
\label{sec:materials}

There are N+1 resources we need to evaluate the systems. For language models
we have selected to get suitable dictionaries from the Internet by seeking
freely available dictionaries for languages of typologically varied
languages.

For creating error models we have created new implementations of the algorithms
to create and modify finite-state error models. For baseline we have created
the basic edit-distance error models by hand and then modified them
automatically to test different variants.

To test the effect of correctness of the source text to speed of
spelling-checker we have fetched of largest freely available open source text
materials from the internet, i.e. Wikipedia for Finnish and English. The
Wikipedia text as itself is good for real-world material as it does contain
wide variety of spelling errors. For a material with more errors, we have used
simple script\footnote{\url{}} to introduce errors at THESE PARAMETERS. Finally
we have used a text corpus from language different than the one being spelled
to ensure that majority of words are not in vocabulary and not fixable by
standard error models, which should provide to be the worst case scenario test
for the spell-checking.

The corpora statistics are as follows: the English Wikipedia dump is X terabytes
in size, it consists of Y tokens of which only Z unique. For our tests we
only used first gigabyte of data. The Finnish Wikipedia is X gigabytes in size
and consists of Y tokens of which Z unique. The Greenlandic Wikipedia is only
X megabytes, consisting Y tokens of which Z unique. For actual tests we only use
first N gigabytes of data for Finnish and English Wikipedia data.

\section{Evaluation}
\label{sec:evaluation}

The evaluations in this section are performed on quad-core Intel Xeon E5450
running at 3~GHz with 64~GiB of RAM memory. The times are averaged over five
test runs in stable server environment with no server processes or running
graphical interfaces or other uses. The test results are measured using the
\texttt{getrusage} C function on a system that supports the maximum resident
stack size \texttt{ru\_maxrss} and user time \texttt{ru\_utime} fields. The times
are also verified with GNU \texttt{time} command. The results for hunspell and
voikkospell processes are only measured with time and top if we do not have
time to modify their source code with added \texttt{getrusage} calls. The
respective versions of the software are voikkospell 3.3, hunspell 1.2.14.

In the Table~\ref{table:error-model-vs-language-speed} we measure the speeds of
the spell-checking process of the native language Wikipedia with real-world
spelling errors and unknown strings. The error model rows are defined as
follows: on the \emph{Reference impl.} row, we test the spell-checking speed of
the hunspell tool for English, and voikkospell tool for Finnish. On the
\emph{edit distance 2} row we use the basic traditional edit distance 2 without
any modifications. On the row \emph{lower order first}, we test applying the
lower order edit distance models first, then iff no results are given advancing
to higher orders up to edit distance XXX. On the \emph{No first edits} row we
use the error model that may not modify the first character of the word or the
first character after compound word boundary. On the \emph{Avoid redundancy}
row we use the error model edit distance 2 with the redundant edit combinations
removed. On the \emph{Avoid redundancy and first edits} rows we use combined
error model of \emph{No first edits} and \emph{Avoid redundancy}
functionalities.  In the tables and formul\ae we routinely use the language
codes to denote the languages: \emph{en} for English, \emph{fi} for Finnish and
\emph{kl} for Greenlandic (Kalaallisut). 

\begin{table}[h]
\begin{center}
\begin{scriptsize}
\begin{tabular}{|l|rrr|}
\hline
\bf Error model & \bf En & \bf Fi & \bf Kl \\ 
\hline
Reference impl. &
10.59&7.94
& --- \\
Generate all edits 2 & 
41.79&1060.71&1345.17
\\
\hline
Edit distance 1 &
0.40 &8.32&6.34
\\
Edit distance 2 &
11.22&346.63&726.70
\\
Edit distance 3 &
11.25&349.09&752.58
\\
No firsts ed 1 & 
0.32&1.74&1.48
\\
No firsts ed 2 &
0.31&1.64&1.46
\\
No firsts ed 3 &
0.31&1.68&1.48
\\
No redundancy or firsts ed 2 &
0.24&1.17&1.46
\\
No redundancy or firsts ed 3 &
0.30&1.26&1.43
\\
Lower order first ed 1 to 2 &
5.49&193.10&676.70
\\
\hline
\end{tabular}
\end{scriptsize}
\end{center}
\caption{\label{table:error-model-vs-language-speed} Effect of language and 
error models to speed}
\end{table}

In the Table~\ref{table:error-model-vs-language-memory} we measure the memory
consumption when performing the same tests. The tests here are also performed
using unmodified native language corpora and with same language and error
models as with previous tests.

\begin{table}[h]
\begin{center}
\begin{scriptsize}
\begin{tabular}{|l|rrr|}
\hline
\bf Error model & \bf En & \bf Fi & \bf Kl \\ 
\hline
Reference impl.   & & & --- \\
\hline
Edit distance 1 &
19 kiB&365 kiB&1774 kiB
\\
Edit distance 2 &
189 kiB&12158 kiB&15911 kiB
\\
Edit distance 3 &
189 kiB&12158 kiB&15911 kiB
\\
No first ed 1 & 
13 kiB&2170 kiB&1600 kiB
\\
No first ed 2 &
13 kiB&2170 kiB&1600 kiB
\\
No first ed 3 &
13 kiB&2170 kiB&1600 kiB
\\
No redundancy or firsts ed 2 &
13 kiB&2170 kiB&1600 kiB
\\
No redundancy or firsts ed 3 &
13 kiB&2170 kiB&1600 kiB
\\
Lower order first ed 1 to 2 &
195 kiB&12308 kiB&16086 kiB
\\
\hline
\end{tabular}
\end{scriptsize}
\end{center}
\caption{\label{table:error-model-vs-language-memory} Effect of language and 
error models to memory consumption}
\end{table}

To measure the degradation of quality when using different error models we
count the proportion of suggestion sets that contain the correct correction
among the corrected strings. For this test we use automatically generated corpus
of spelling errors to get the large-scale results. For English and Finnish we
have also used smaller set of original errors in the unmodified corpora that
were hand-corrected by native speaker; for Greenlandic we did not have a native
speaker available for this purpose. The numbers from real-world errors are 
indicated in parentheses.

\begin{table}[h]
\begin{center}
\begin{scriptsize}
\begin{tabular}{|l|rrrl|}
\hline
\bf Error model & \bf En & \bf Fi & \bf Kl & (Notes) \\ 
\hline
Reference impl.   & & & --- & en: hunspell, fi: voikko, kl: n/a \\
\hline
Edit distance 1                             & & & & \\
Edit distance 2                             & & & & \\
Edit distance 3                             & & & & \\
No first edits ed 1                         & & & & \\
No first edits ed 2                         & & & & \\
No first edits ed 3                         & & & & \\
Lower order first, ed 1-2                   & & & & \\
Avoid redundancy ed 2                       & & & & \\
Avoid redundancy ed 3                       & & & & \\
Avoid redundancy and first edits ed 2       & & & & \\
Avoid redundancy and first edits ed 3       & & & & \\
Generate all edits 1                        & & & & \\
Generate all edits 2                        & & & & \\
\hline
\end{tabular}
\end{scriptsize}
\end{center}
\caption{\label{table:error-model-vs-language} Effect of language and 
error models to quality}
\end{table}

Finally we measure how the text type used will effect the speed of the
spell-checking. As the best-case scenario we use the unmodified texts of
Wikipedia, which contain probably the most realistic native language
speaker-like typing error distribution. For text with some more errors, where
majority of errors should be recoverable we use our automatically generated
errors in the Wikipedia texts. Finally to see the performance on worst case
scenario where most of the words have unrecoverable spelling errors we use the
texts from other language, in this case English texts for Finnish and 
Greenlandic spell-checking and Finnish texts for English spell-checking, which
will likely give us the nearly lower bounds of the performance. All of the
tests in this category were performed with error models foo which gave us 
the best speed/quality ratio in the previous tests.

\begin{table}[h]
\begin{center}
\begin{scriptsize}
\begin{tabular}{|l|rrrl|}
\hline
\bf Error model & \bf En & \bf Fi & \bf Kl & (Notes) \\ 
\hline
Native Lang. Corpus      & & & & \\
Added Automatic Errors   & & & & \\
Text in Another language & & & & \\
\hline
\end{tabular}
\end{scriptsize}
\end{center}
\caption{\label{table:language-vs-text-type} Effect of text type on
error models to speed}
\end{table}

In Table~\ref{table:automata-sizes} we also summarize the sizes of automata in
terms of structural elements; the first number is the amount of vertices and the
second number is the amount of edges. The size of alphabets $|\Sigma|$
for the automata is: $|\Sigma_{en}| = $, $|\Sigma_{fi}| = $ and $|\Sigma_{kl} =
$.

\begin{table}[h]
\begin{center}
\begin{scriptsize}
\begin{tabular}{|l|rrrl|}
\hline
\bf Automaton & \bf En & \bf Fi & \bf Kl & (Notes) \\ 
\hline
Edit distance 1                             & & & & \\
Edit distance 2                             & & & & \\
Edit distance 3                             & & & & \\
No first edits ed 1                         & & & & \\
No first edits ed 2                         & & & & \\
No first edits ed 3                         & & & & \\
Lower order first, ed 1-2                   & & & & \\
Avoid redundancy ed 1                       & & & & \\
Avoid redundancy ed 2                       & & & & \\
Avoid redundancy ed 3                       & & & & \\
Avoid redundancy and first edits ed 1       & & & & \\
Avoid redundancy ed 2                       & & & & \\
Avoid redundancy ed 3                       & & & & \\
Generate all edits 1                        & & & & \\
Generate all edits 2                        & & & & \\
\hline
\end{tabular}
\end{scriptsize}
\end{center}
\caption{\label{table:automata-sizes} The sizes of automata (nodes, then edges)}
\end{table}


\section{Conclusions}
\label{sec:conclusions}

In this paper we have shown that finite-state spell-checking is suitable for
general use even with those language models that have been deemed
unimplementable for other contemporary methods of implementing spell-checking.

% \section*{Acknowledgements} 

% We thank the anonymous reviewers for their comments and the HFST research
% team for fruitless discussions on the article's topics.

\bibliographystyle{acl2012}
\bibliography{fsmnlp2012}

\end{document}
% vim: set spell:
