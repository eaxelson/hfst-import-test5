\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage[utf8x]{inputenc}
\usepackage{multirow}
\usepackage{caption}
\usepackage{url}
%
\begin{document}
%
\title{Using HFST for Creating Computational Linguistic Applications}
%
\author{Krister Lind\'{e}n \and Erik Axelson \and Senka Drobac \and\\
Sam Hardwick \and Tommi A Pirinen \and Miikka Silfverberg}

\institute{University of Helsinki\\
Department of Modern Languages\\
Unioninkatu 40 A\\
FI-00014 Helsingin yliopisto, Finland\\
\email{\{krister.linden, erik.axelson, senka.drobac, sam.hardwick,\\
tommi.pirinen, miikka silfverberg\}@helsinki.fi}}

\maketitle

\begin{abstract}
\sloppy HFST – Helsinki Finite-State Technology (\url{hfst.sf.net})
is a framework for compiling and applying linguistic descriptions
with finite-state
methods. HFST currently connects some of the most important finite-state
tools for creating morphologies and spellers into one open-source
platform and supports extending and improving the descriptions with
weights to accommodate the modeling of statistical information. HFST
offers a path from language descriptions to efficient language
applications.

HFST is designed for compiling morphologies and for that purpose it
contains open-source replicas of xfst, lexc and twolc which are
well-known and well-researched tools for morphology building. They
support both parallel and cascaded application of transducers. In
addition, HFST offers the capability to train and apply part-of-speech
taggers on top of the morphologies using weighted finite-state transducers.

With the morphology and tagger capabilities a number of applications
have been created, e.g. spellers for close to 100 languages and
hyphenators for approximately 40 different languages. The spellers were
derived from open-source dictionaries and integrated with OpenOffice and
LibreOffice. E.g. a full-fledged Greenlandic speller, which is a
polyagglutinating language, is currently available only via HFST for
OpenOffice. Using the tagger capability of HFST, we have created an
improved spelling suggestion mechanism for words in context as well as
better predictive text input for mobile phones for highly inflecting
languages like Finnish. Other writer’s tools created with HFST include
inflecting thesauri and translation dictionaries. We also offer lexicon
compilation and preprocessing for the Apertium machine translation
software.

For the processing of large corpora, e.g. for text indexing purposes, a
high-performing look-up facility is provided with HFST offering
110.000-440.000 words per second of morphological processing. A recent
extension of the look-up facility offers a utility to create named
entity recognizers for information extraction purposes on top of the
lookup. 
\keywords{no, keywords, yet}
\end{abstract}

\section*{Introduction}
% Krister

\section{Building Morphologies}

\subsection{Introduction}

One of the earliest and most important goals of the HFST project has
been to provide open-source utilities for compiling full-fledged
morphological analyzer, which can be used in constructing spellers,
taggers and other language technological utilities of good
quality. The Xerox toolkit \cite{beesley/2003} is among the most
widely used frameworks for constructing morphological utilities. The
toolkit is used to compile linguistic description into morphological
analyzers. More specifically, Xerox tools include the finite-state
lexicon compiler lexc, the two-level rule compiler twolc and the
cascading replace rule compiler xfst. HFST includes the tools
hfst-lexc, hfst-twolc and hfst-xfst, which provide full backward
compatibility with Xerox tools and augment their functionality.

An lexicon-file for the lexicon compiler hfst-lexc the morphotax of a
language using sub-lexicons which are lists of morphs. Later a rule
component is used to realize phonological changes which occur at the
boundaries of morphs.

The rule compilers hfst-xfst and hfst-twolc provide partially the same
functionality. Both are used to realize morphophonological variations
on an hfst-lexc lexicon. The difference between the tools is that
hfst-xfst rules are applied in succession gradually altering the
lexicon and hfst-twolc rules are applied as parallel constraints,
which limit the realizations of morphophonemes used in the hfst-lexc
lexicon..

\subsection{Parallel Rules with Negative Contexts and Regular Expression Centers}

The rule compiler hfst-twolc provides backward compatibility with the
Xerox tool twolc, but it augments twolc functionality by providing two
new types of rules. In hfst-twolc rules can have centers which are
regular expressions and the can have negative contexts.

\begin{figure}
\begin{verbatim}
"Rule with negative context"
x:y <=> a b _     ;
        except
            _ ( c ) d ;

"Rule without negative context"
x:y <=> a b _ [ ? - [ c | d ] | c [ ? - d ] | .#. ] ;
\end{verbatim}
\caption{Negative context rule and corresponding traditional two-level
  rule}\label{negative-context-rule}
\end{figure}

In traditional two-level rules it can be very difficult to express
that a certain alternation should not occur in a given
context. Sometimes conflict resolution of two-level rules handles
this, but conflict resolution works only if rules can be ordered into
chains of sub cases. Often this can be difficult to accomplish,
especially for grammar writers who are not especially well acquainted
to writing regular expressions.

Using an extension to the xerox two-level rule syntax in hfst-twolc,
it is possible to formulate rules with negative context, i.e. context
which prohibit the triggering of the
rule. Figure~\ref{negative-context-rule} shows a schematic example of
a negative context rule and a traditional xerox style rule, which has
the same effect as the rule with the negative context.

\begin{figure}
\begin{verbatim}
"ZZ normally realized as xy except between two a:s"
<[ Z:x Z:y ]> <==> _      ;
                   except
                   a _ a  ;

"Swap x and y between two a:s"
<[ Z:y Z:x ]> <==> a _ a ; 
\end{verbatim}
\caption{Rule with regular expression center and two auxiliary rules which}
\end{figure}

Regular expression centers allow rules to govern longer segments than
single symbols. This can be useful when describing languages, with
complex allomorphy.

\subsection{Cascaded Rules: Explanations and Examples}
% Senka
HFST replace rules provide backward compatibility with XFST replace rules, described in Kempe and Karttunen \cite{Kempe96parallelreplacement} and Finite State Morphology book \cite{beesley/2003}. Although they share the same notation, HFST replace rules were developed on a concept of Generalized Lenient Composition, described in Yli-Jyr\"{a} \cite{YliJyra/2008b}. 

In this paper section, there will be described how to use Replace Rules with HFST tools. For detailed description of each rule, see Beesley and Karttunen \cite{beesley/2003}.



% Simple rules

\textbf{Simple rules.} Simple right arrow replace rule,
\begin{equation}
A \rightarrow\ B
\end{equation}

where A and B are regular expressions that describe languages, states that A in upper language maps to B in lower language.

Replace rules can be compiled into transducer using HFST tool \textbf{hfst-regexp\-2fst}.
This tool takes regular expresion as input and gives a corresponding transducer written in a binary file as output. To convert transducers from binary format to text format, there is a HFST tool \textbf{hfst-fst2txt}. Therefore, the upper rule could be compiled as in Figure~\ref{fig:simple_replace}.

\begin{figure} [h!]
\begin{verbatim}
$ echo "A -> B ;" | hfst-regexp2fst | hfst-fst2txt
\end{verbatim}
\caption{Compiling simple replace rule}
\label{fig:simple_replace}
\end{figure}


The regular expression can be read from a file, or saved to a file (Figure~\ref{fig:read_from_file}). 

\begin{figure} [h!]
\begin{verbatim}
$ echo "A -> B ;" > regex
$ hfst-regexp2fst -i regex -o transducer
$ hfst-fst2txt transducer
\end{verbatim}
\caption{Reading from, and writing to a file}
\label{fig:read_from_file}
\end{figure}


Rules can be applied to any language by using composition. By composing previous rule \verb!A -> B! to a word \verb!ABCD!, the result is the transducer on Figure~\ref{fig:replace_compose}. It has 5 states (0 -- 4), and only state 4 is final. The \textbf{hfst-regexp2fst's} default output transducer format is \textbf{tropical\_openfst}, which has a support for weights. Since weights aren't used in replace rules, in this example all of them have value 0.000000. Other formats that can be used with this, and other HFST tools, are \textbf{sfst} and \textbf{foma}.

\begin{figure} [h!]
\begin{verbatim}
$ echo "A B C D .o. A -> B ;" | hfst-regexp2fst | hfst-fst2txt
0       1       A       B       0.000000
1       2       B       B       0.000000
2       3       C       C       0.000000
3       4       D       D       0.000000
4       0.000000
\end{verbatim}
\caption{Composing rule to a word}
\label{fig:replace_compose}
\end{figure}


\begin{figure} [h!]
\begin{verbatim}
$ echo "c a t .o. c a t -> c a t s  ;" |
> hfst-regexp2fst -f sfst | hfst-fst2txt
0       1       c       c
1       2       a       a
2       3       t       t
3       4       @0@     s
4
\end{verbatim}
\caption{Using sfst transducer format}
\label{fig:sfst_format}
\end{figure}



% Context

\textbf{Context.} Every rule can have a context in which the replacement is made. Just like A and B, L and R are also regular expresions that describe languages. Therefore, A will be mapped with B only, and only if, it is between L and R.
\begin{equation}
A \rightarrow\ B\ ||\ L \_\  R
\end{equation}
 
Also, multiple context pairs are supported, when separated with comma.
\begin{equation}
A \rightarrow\ B\ ||\ L_1 \_\  R_1 ,\ \ldots\ ,\ L_i \_\  R_i
\end{equation}

In Figure~\ref{fig:multiple_contexts}, the rule expression says that \verb!a! in upper language is mapped with \verb!b! in lower language when between \verb!m! and \verb!n!, or in front of \verb!b!. In word \verb!manaab!, first and last \verb!a! are mapped to \verb!b!, because they are in betwwen corresponding contexts, but second \verb!a! is kept unchanged.

\begin{figure} [h!]
\begin{verbatim}
$ echo " m a n a a b .o. a -> b || m _ n , _ b;" |
> hfst-regexp2fst | hfst-fst2txt
0       1       m       m       0.000000
1       2       a       b       0.000000
2       3       n       n       0.000000
3       4       a       a       0.000000
4       5       a       b       0.000000
5       6       b       b       0.000000
6       0.000000
\end{verbatim}
\caption{Replace rule between two contexts}
\label{fig:multiple_contexts}
\end{figure}

\begin{table} [h!]
\centering
\begin{tabular}{ | c | c | }
\hline
\ \verb!||!\ & \ both contexts are taken from the upper language \\ \hline
\ \verb!//!\ & \ left context is taken from the lower language, right from the upper \\ \hline
\ \verb!\\!\ & \ left context is taken from the upper language, right from the lower \\ \hline
\ \verb!\/!\ & \ both contexts are taken from the lower language. \\ \hline
\end{tabular}
\caption{Different context directions in Replace Rules}
\label{tab:context_directions}
\end{table}

In every replace rule, where A is upper, and B lower language, there are four context directions that can be used with replace rules. For example, when \ \verb!//!\ sign is used as context orientation operator, left context will be taken from lower language. It means that it is posible for replace function to write it's own context. This is shown in Figure~\ref{fig:context_orientation}. 

\begin{figure} [h!]
 \begin{verbatim}
$ echo " b a a .o. a -> b // b _ ;" | ./hfst-regexp2fst | hfst-fst2txt
0       1       b       b       0.000000
1       2       a       b       0.000000
2       3       a       b       0.000000
3       0.000000
\end{verbatim}
\caption{Replace rule writes it's own context}
\label{fig:context_orientation}
\end{figure}




% Other replace functions

\textbf{Other replace functions.} In all examples is used the right arrow replace operator, but there are many other operators that can be used. All the operators listed in Table~\ref{tab:replace_operators} have their left arrow version, which are inversion of the right operator. Furthermore, all the rules can be used with epenthesis \verb![. .]! and markup \verb!...! operators. Epenthesis operator should be used with empty strings to avoid replacing infintly many epsilons, while markup operator is used to insert markers around a word.

\begin{table} [h!]
\centering
\begin{tabular}{| c | c |} 
\hline
Right replace operators & Replace function \\ \hline\hline
\verb!->!   & Replace \\ \hline
\verb!(->)! & Replace optional \\ \hline
\verb!@->!  & Longest match from left to right \\ \hline
\verb!->@!  & Longest match from right to left \\ \hline
\verb!@>!   & Shortest match from left to right \\ \hline
\verb!>@!   & Shortest match from right to left \\ \hline
\end{tabular}
\caption{List of right replace operators that can be used in HFST}
\label{tab:replace_operators}
\end{table}



\begin{figure} [h!]
 \begin{verbatim}
$ echo " a a a .o. [.a*.] @-> b ;" | hfst-regexp2fst > a.fst
$ echo " b a a b .o. a @-> %[ ... %] ;" | hfst-regexp2fst > b.fst
\end{verbatim}
\caption{Epenthesis and markup operators}
\label{fig:epenthesis_markup}
\end{figure}


% Parallel rules

\textbf{Parallel rules.} Paralel rules are used to have multiple replacements in the same time. The general parallel replace rule expression consists of individual replace rules divided with two commas.
\begin{equation}
A_1 \rightarrow\ B_1\ ||\ L_1 \_\  R_1\ ,,\ \ldots\ ,,\ A_i \rightarrow\ B_i\ ||\ L_i \_\ R_i
\end{equation}

In XFST, all rules in parallel rule expression have to have the same format. They need to have the same arrow and the same context layout. In HFST, the restraint that all the rules need to have the same arrow is kept, but the context format for each rule can differ from each other. Therefore, the rule expression in Figure ~\ref{fig:parallel_rules} would not be allowed in XFST, but is valid in HFST.
\begin{figure}
 \begin{verbatim}
$  echo " a -> b || m _ n ,, c -> d ;" | ./hfst-regexp2fst | hfst-fst2txt
\end{verbatim}
\caption{Parallel rules with different contexts}
\label{fig:parallel_rules}
\end{figure}




\subsection{Morphosyntax and Morphological Formul\ae}

Morphosyntax is the component dealing with morphological combinatorics in
language descriptions. This concerns word-formation processes, such as
affixation, compounding and more. There are numerous more or less widely
accepted formalisms for describing the morphosyntax in natural language
processing applications, such as
hunspell\footnote{\url{http://hunspell.sf.net}} (and its older *spell
relatives), apertium lttoolbox\footnote{\url{http://apertium.sf.net}} or Xerox
lexc\cite{beesley/2003}. The HFST tool set contains parsers and compilers to
read descriptions in those languages and compile a finite-state automaton for
rest of the HFST tools to process out from them
\cite{pirinen/il/2010,pirinene/2009/sfcm,pirinen/2012/lrec}. In this sections
we draw shortly summarise the common features of the algorithms used to compile
all the descriptions and generalise the formula over morphosyntax for
finite-state automata, described fully in terms of standard finite-state
operations.

It is true for all the contemporary morphosyntax implementations that they more
or less draw from item-and-arrangement style combinatorics over sets of
morphs or morphemes. In general form such a system can be described as a
disjunction of morphs repeated infinitely over each other, combined with
morphosyntactic filter describing precisely the right combinations of morphemes.
Both morphemes and the filters can be trivially described in finite-state form.

As an example, starting from a morpheme, that is a path or a language, e.g.  a
morpheme \emph{dog} would be automaton encoding a path \texttt{d o g}, and
\emph{cat} path \texttt{c a t}, similarly a plural marker \emph{-s} of English
would be a path \texttt{s} whereas singular marker \emph{$\emptyset$}
\texttt{$\varepsilon$} (marking empty morph). For morphosyntax of this language
\emph{dog} and \emph{cat} would form a set called e.g. \emph{Nouns} and
\emph{$\emptyset$} and \emph{s} a set of called \emph{Number}. A valid
morphosyntax here would be Start $\rightarrow$ Nouns $\rightarrow$ Number
$\rightarrow$ End. Now, that morphosyntax can be compiled as finite-state
automaton such that we replace $\rightarrow$ in the former description with the
morphs. Then we decorate the actual morphs with markers for e.g. starts of the
sets named \emph{Nouns} and \emph{Number}. The final language is now simply
composition of that morphosyntax over the kleene plus closure of morpheme sets.


\subsubsection{For Lexicographers}
% Tommi

\subsubsection{For Grammarians}
% Tommi & Miikka

\subsection{Performance}
% Erik

In table X we present compilation times for different morphologies using 
different HFST backends. The morphologies are OMorFi for Finnish, Morphisto 
for German, Morph-it for Italian, Swelex for Swedish and TrMorph for Turkish 
(todo: add footnotes). OMorFi, Morphisto and Morph-it contain several rules for
inflection and compounding. Morph-it and Swelex are basically word-lists.


\begin{table}
  \caption{Compilation times for different morphologies with
    different HFST backends. The times are expressed in minutes and seconds.}
  \label{tab:compilation_times}
  \begin{tabular}{ c  c  c  c }
    \hline
    Morphology & SFST & OpenFst & foma \\ \hline
    Finnish & 2:48 & 7:52 & 1:52 \\ \hline
    German & 2:12 & 7:45 & 1:33 \\ \hline
    Italian & 0:30 & 2:24 & 0:31 \\ \hline
    Swedish & 0:13 & 0:49 & 0:13 \\ \hline
    Turkish & 0:12 & 0:40 & 0:05 \\ \hline
    \end{tabular}
\end{table}


In table X we also present the compilation times for Finnish and German compared
with the results that we obtained in our previous benchmarking. The backend
versions are also shown.

\begin{table}
  \caption{Compilation times for different morphologies with
    different HFST backends and versions. 
    The times are expressed in minutes and seconds.}
  \label{tab:compilation_times_versions}
  \begin{tabular}{ c  c  c  c }
%  \multicolumn{4}{c}{Compilation times} \\
\hline
  Back-End                 & version  & Finnish  & German \\ \hline
  \multirow{2}{*}{SFST}    & 1.4.2    & 5:02     & 6:39 \\
                           & 1.4.6    & 2:48     & 2:12 \\ \hline
  \multirow{2}{*}{OpenFst} & 1.2.7    & 6:51     & 6:28 \\
                           & 1.2.10   & 7:52     & 7:45 \\ \hline
  \multirow{2}{*}{foma}    & ?        & 1:49     & 1:29 \\
                           & 0.1.16   & 1:52     & 1:33 \\
\hline
  \end{tabular}

\end{table}

It can be clearly seen that the performance of HFST with SFST as backend 
has improved. The current compilation time of the Finnish morphology has almost
halved. The compilation time of the German morphology is only one third of the
result at previous benchmarking. 
This is because SFST has new efficient minimization and composition functions
developed in collaboration with the HFST team.

The performance of HFST with OpenFst as backend has become slower. It is not
clear whether this is because of the newer version of OpenFst or changes in the 
actual HFST code (todo: find out).

The performance of HFST with foma has stayed almost the same, only a minor
growth of couple of seconds can be noticed. 
 

\section{Building Taggers}

\subsection{Introduction}
% Miikka

\begin{itemize}
\item Possible to construct HMM type taggers using different
  combinations of tags and wordforms~\cite{Silfverberg/2010/IceTal}
  and \cite{Silfverberg/2011}.
\item Accuracy comparable with TnT~\cite{Brants:2000}.
\item There are some new optimizations to the lexical model and
  sequence model. Especially we implement a version of the Viterbi
  algorithm for weighted treansducers.
\end{itemize}


\subsection{Including Morphologies without Harmonizing Tagsets}
% Miikka

\begin{itemize}
\item Tnt-type guesser work poorly for agglutinative languages.
\item Paradigm-based guessers for agglutinative languages using
  morphological analyzers work better.
\item Differing tag sets are a problem. It is sometimes difficult to
  find good translations between tag sets because the underlying
  linguistic description can differ a lot.
\item HFST provides a way to use a morphological analyzer to construct
  a paradigm based guesser, without harmonizing tag sets.
\item Words are transformed to their corresponding analysis sets and
  the analysis sets are associated with tags and corresponding
  conditional probabilities.
\item When a previously unseen word is encountered while tagging, it
  is transformed into its set of analyses and the tag probabilities
  for that set are used.
\item For words unknown to the morphological analyzer or for words
  whose analysis set does not figure in the training data, a
  suffix-based guesser is used.
\end{itemize}

\subsection{Optimization}
% Miikka
\begin{itemize}
\item Viterbi-style optimization.
\item Beam-search for Finnish, where the tag set is huge.
\end{itemize}

\section{Applying Transducers}

\subsection{Introduction}
% Tommi

\subsection{Spellers}

The task of finite-state spell-checking is well researched and documented. It
consists mainly of two phases, identifying incorrect word forms and creating
suggestions for corrections. For incorrect word-forms there are two types of
mistakes, non-word spelling errors, such as writing \emph{cta} where \emph{cat}
is meant, and real-word spelling errors, such as writing \emph{there} where
\emph{their} is intended. The method for finding former in finite-state system
is simply applying the dictionary to the text word by word, any unrecognised
string not belonging to the language of the dictionary automaton is a non-word
spelling error. For real-word errors a statistical n-gram model or syntactic
parser is typically required\cite{}. To correct a spelling error in finite-state
system, a two-tape automaton modeling the typing errors should be applied to
the misspelt string to get set of potential corrections\cite{pirinen/lrec/2010}.
For practical purposes the error model can also be implemented as
fuzzy finite-state traversal algorithm or similar methods\cite{,}. The result
of the correction step is a set of word-forms that are correct in the
language of the spell-checking dictionary. Another related task is to rank this
set to provide the most likely corrections first for the end-user of spelling
correction system. A trivial way to perform such ranking would be to use
unigram \cite{pirinen/lrec/2010} or n-gram probabilities of the words 
\cite{mays/1991} or word-form analyses \cite{pirinen/cicling/2012}.

\subsubsection{Creating Spellers}
% Tommi

The creation of finite-state speller requires compiling of (at least) two
automata: a dictionary that contains the correctly spelt word-forms and the
error model that can rewrite misspelt word-forms into correctly spelled ones.
The former automaton can be as simple as a reference corpus, containing larger
quantities of correctly spelled words and (possibly) smaller quantities of
misspelt ones\cite{norvig/2010}. Also more elaborate dictionaries, such as
morphological analysers described in sections \ref{,,} can be used, and also
trained for spell-checking purposes with reference corpora without any big
modifications to underlying implementation\cite{pirinen/lrec/2010}.

For the error-model we can trivially construct an automaton corresponding to
Levenshtein edit distance algorithm\cite{,}. For more elaborate error models
it is possible to use hunspell algorithms as automata \cite{pirinen/il/2010} or
construct further extensions by hand \cite{pirinen/lrec/2010}. Given a possibly
aligned error corpus it is also possible to construct a weighted error model
automaton automatically \cite{}.

\subsubsection{Checking Strings and Generating Suggestions}
% Sam

\subsubsection{Ranking Suggestions}
% Tommi & Miikka

Applying the error model and the language model to the spelling error strings,
a result is typically an ordered set of corrected strings with some probability
associated to each correction. After applying the contextless error correction
described earlier it is possible to use context words and their potential
analyses to re-rank the corrections \cite{pirinen/cicling/2012}.

\subsection{Synonym and Translation Dictionaries}
% Krister

\section{Extending Transducers for Pattern Matching}
% Sam

\section{Discussion}

\section{Conclusion}

\subsubsection*{Acknowledgments}

\bibliographystyle{splncs03}

\bibliography{hfst2012}

\end{document}
% vim: set spell:
