\documentclass{llncs}
\usepackage{llncsdoc}
\usepackage[utf8x]{inputenc}
\usepackage{multirow}
\usepackage{caption}
\usepackage{url}
%
\begin{document}
%
\title{Using HFST for Creating Computational Linguistic Applications}
%
\author{Krister Lind\'{e}n \and Erik Axelson \and Senka Drobac \and\\
Sam Hardwick \and Tommi A Pirinen \and Miikka Silfverberg}

\institute{University of Helsinki\\
Department of Modern Languages\\
Unioninkatu 40 A\\
FI-00014 Helsingin yliopisto, Finland\\
\email{\{krister.linden, erik.axelson, senka.drobac, sam.hardwick,\\
tommi.pirinen, miikka silfverberg\}@helsinki.fi}}

\maketitle

\begin{abstract}
\sloppy HFST – Helsinki Finite-State Technology (\url{hfst.sf.net})
is a framework for compiling and applying linguistic descriptions
with finite-state
methods. HFST currently connects some of the most important finite-state
tools for creating morphologies and spellers into one open-source
platform and supports extending and improving the descriptions with
weights to accommodate the modeling of statistical information. HFST
offers a path from language descriptions to efficient language
applications.

HFST is designed for compiling morphologies and for that purpose it
contains open-source replicas of xfst, lexc and twolc which are
well-known and well-researched tools for morphology building. They
support both parallel and cascaded application of transducers. In
addition, HFST offers the capability to train and apply part-of-speech
taggers on top of the morphologies using weighted finite-state transducers.

With the morphology and tagger capabilities a number of applications
have been created, e.g. spellers for close to 100 languages and
hyphenators for approximately 40 different languages. The spellers were
derived from open-source dictionaries and integrated with OpenOffice and
LibreOffice. E.g. a full-fledged Greenlandic speller, which is a
polyagglutinating language, is currently available only via HFST for
OpenOffice. Using the tagger capability of HFST, we have created an
improved spelling suggestion mechanism for words in context as well as
better predictive text input for mobile phones for highly inflecting
languages like Finnish. Other writer’s tools created with HFST include
inflecting thesauri and translation dictionaries. We also offer lexicon
compilation and preprocessing for the Apertium machine translation
software.

For the processing of large corpora, e.g. for text indexing purposes, a
high-performing look-up facility is provided with HFST offering
110.000-440.000 words per second of morphological processing. A recent
extension of the look-up facility offers a utility to create named
entity recognizers for information extraction purposes on top of the
lookup. 
\keywords{no, keywords, yet}
\end{abstract}

\section*{Introduction}
% Krister

\section{Building Morphologies}

\subsection{Introduction}

One of the earliest and most important goals of the HFST project has
been to provide open-source utilities for compiling full-fledged
morphological analyzer, which can be used in constructing spellers,
taggers and other language technological utilities of good
quality. The Xerox toolkit \cite{beesley/2003} is among the most
widely used frameworks for constructing morphological utilities. The
toolkit is used to compile linguistic description into morphological
analyzers. More specifically, Xerox tools include the finite-state
lexicon compiler lexc, the two-level rule compiler twolc and the
cascading replace rule compiler xfst. HFST includes the tools
hfst-lexc, hfst-twolc and hfst-xfst, which provide full backward
compatibility with Xerox tools and augment their functionality.

An lexicon-file for the lexicon compiler hfst-lexc the morphotax of a
language using sub-lexicons which are lists of morphs. Later a rule
component is used to realize phonological changes which occur at the
boundaries of morphs.

The rule compilers hfst-xfst and hfst-twolc provide partially the same
functionality. Both are used to realize morphophonological variations
on an hfst-lexc lexicon. The difference between the tools is that
hfst-xfst rules are applied in succession gradually altering the
lexicon and hfst-twolc rules are applied as parallel constraints,
which limit the realizations of morphophonemes used in the hfst-lexc
lexicon..

\subsection{Parallel Rules with Negative Contexts and Regular Expression Centers}

The rule compiler hfst-twolc provides backward compatibility with the
Xerox tool twolc, but it augments twolc functionality by providing two
new types of rules. In hfst-twolc rules can have centers which are
regular expressions and the can have negative contexts.

\begin{figure}
\begin{verbatim}
"Rule with negative context"
x:y <=> a b _     ;
        except
            _ ( c ) d ;

"Rule without negative context"
x:y <=> a b _ [ ? - [ c | d ] | c [ ? - d ] | .#. ] ;
\end{verbatim}
\caption{Negative context rule and corresponding traditional two-level
  rule}\label{negative-context-rule}
\end{figure}

In traditional two-level rules it can be very difficult to express
that a certain alternation should not occur in a given
context. Sometimes conflict resolution of two-level rules handles
this, but conflict resolution works only if rules can be ordered into
chains of sub cases. Often this can be difficult to accomplish,
especially for grammar writers who are not especially well acquainted
to writing regular expressions.

Using an extension to the xerox two-level rule syntax in hfst-twolc,
it is possible to formulate rules with negative context, i.e. context
which prohibit the triggering of the
rule. Figure~\ref{negative-context-rule} shows a schematic example of
a negative context rule and a traditional xerox style rule, which has
the same effect as the rule with the negative context.

\begin{figure}
\begin{verbatim}
"ZZ normally realized as xy except between two a:s"
<[ Z:x Z:y ]> <==> _      ;
                   except
                   a _ a  ;

"Swap x and y between two a:s"
<[ Z:y Z:x ]> <==> a _ a ; 
\end{verbatim}
\caption{Rule with regular expression center and two auxiliary rules which}
\end{figure}

Regular expression centers allow rules to govern longer segments than
single symbols. This can be useful when describing languages, with
complex allomorphy.

\subsection{Cascaded Rules: Explanations and Examples}
% Senka

\subsection{Morphosyntax and Morphological Formul\ae}

Morphosyntax is the component dealing with morphological combinatorics in
language descriptions. This concerns word-formation processes, such as
affixation, compounding and more. There are numerous more or less widely
accepted formalisms for describing the morphosyntax in natural language
processing applications, such as
hunspell\footnote{\url{http://hunspell.sf.net}} (and its older *spell
relatives), apertium lttoolbox\footnote{\url{http://apertium.sf.net}} or Xerox
lexc\cite{beesley/2003}. The HFST tool set contains parsers and compilers to
read descriptions in those languages and compile a finite-state automaton for
rest of the HFST tools to process out from them
\cite{pirinen/il/2010,pirinene/2009/sfcm,pirinen/2012/lrec}. In this sections
we draw shortly summarise the common features of the algorithms used to compile
all the descriptions and generalise the formula over morphosyntax for
finite-state automata, described fully in terms of standard finite-state
operations.

It is true for all the contemporary morphosyntax implementations that they more
or less draw from item-and-arrangement style combinatorics over sets of
morphs or morphemes. In general form such a system can be described as a
disjunction of morphs repeated infinitely over each other, combined with
morphosyntactic filter describing precisely the right combinations of morphemes.
Both morphemes and the filters can be trivially described in finite-state form.

As an example, starting from a morpheme, that is a path or a language, e.g.  a
morpheme \emph{dog} would be automaton encoding a path \texttt{d o g}, and
\emph{cat} path \texttt{c a t}, similarly a plural marker \emph{-s} of English
would be a path \texttt{s} whereas singular marker \emph{$\emptyset$}
\texttt{$\varepsilon$} (marking empty morph). For morphosyntax of this language
\emph{dog} and \emph{cat} would form a set called e.g. \emph{Nouns} and
\emph{$\emptyset$} and \emph{s} a set of called \emph{Number}. A valid
morphosyntax here would be Start $\rightarrow$ Nouns $\rightarrow$ Number
$\rightarrow$ End. Now, that morphosyntax can be compiled as finite-state
automaton such that we replace $\rightarrow$ in the former description with the
morphs. Then we decorate the actual morphs with markers for e.g. starts of the
sets named \emph{Nouns} and \emph{Number}. The final language is now simply
composition of that morphosyntax over the kleene plus closure of morpheme sets.


\subsubsection{For Lexicographers}
% Tommi

\subsubsection{For Grammarians}
% Tommi & Miikka

\subsection{Performance}
% Erik

In table X we present compilation times for different morphologies using 
different HFST backends. The morphologies are OMorFi for Finnish, Morphisto 
for German, Morph-it for Italian, Swelex for Swedish and TrMorph for Turkish 
(todo: add footnotes). OMorFi, Morphisto and Morph-it contain several rules for
inflection and compounding. Morph-it and Swelex are basically word-lists.


\begin{table}
  \caption{Compilation times for different morphologies with
    different HFST backends. The times are expressed in minutes and seconds.}
  \label{tab:compilation_times}
  \begin{tabular}{ c  c  c  c }
    \hline
    Morphology & SFST & OpenFst & foma \\ \hline
    Finnish & 2:48 & 7:52 & 1:52 \\ \hline
    German & 2:12 & 7:45 & 1:33 \\ \hline
    Italian & 0:30 & 2:24 & 0:31 \\ \hline
    Swedish & 0:13 & 0:49 & 0:13 \\ \hline
    Turkish & 0:12 & 0:40 & 0:05 \\ \hline
    \end{tabular}
\end{table}


In table X we also present the compilation times for Finnish and German compared
with the results that we obtained in our previous benchmarking. The backend
versions are also shown.

\begin{table}
  \caption{Compilation times for different morphologies with
    different HFST backends and versions. 
    The times are expressed in minutes and seconds.}
  \label{tab:compilation_times_versions}
  \begin{tabular}{ c  c  c  c }
%  \multicolumn{4}{c}{Compilation times} \\
\hline
  Back-End                 & version  & Finnish  & German \\ \hline
  \multirow{2}{*}{SFST}    & 1.4.2    & 5:02     & 6:39 \\
                           & 1.4.6    & 2:48     & 2:12 \\ \hline
  \multirow{2}{*}{OpenFst} & 1.2.7    & 6:51     & 6:28 \\
                           & 1.2.10   & 7:52     & 7:45 \\ \hline
  \multirow{2}{*}{foma}    & ?        & 1:49     & 1:29 \\
                           & 0.1.16   & 1:52     & 1:33 \\
\hline
  \end{tabular}

\end{table}

It can be clearly seen that the performance of HFST with SFST as backend 
has improved. The current compilation time of the Finnish morphology has almost
halved. The compilation time of the German morphology is only one third of the
result at previous benchmarking. 
This is because SFST has new efficient minimization and composition functions
developed in collaboration with the HFST team.

The performance of HFST with OpenFst as backend has become slower. It is not
clear whether this is because of the newer version of OpenFst or changes in the 
actual HFST code (todo: find out).

The performance of HFST with foma has stayed almost the same, only a minor
growth of couple of seconds can be noticed. 
 

\section{Building Taggers}

\subsection{Introduction}
% Miikka

\begin{itemize}
\item Possible to construct HMM type taggers using different
  combinations of tags and wordforms~\cite{Silfverberg/2010/IceTal}
  and \cite{Silfverberg/2011}.
\item Accuracy comparable with TnT~\cite{Brants:2000}.
\item There are some new optimizations to the lexical model and
  sequence model. Especially we implement a version of the Viterbi
  algorithm for weighted treansducers.
\end{itemize}


\subsection{Including Morphologies without Harmonizing Tagsets}
% Miikka

\begin{itemize}
\item Tnt-type guesser work poorly for agglutinative languages.
\item Paradigm-based guessers for agglutinative languages using
  morphological analyzers work better.
\item Differing tag sets are a problem. It is sometimes difficult to
  find good translations between tag sets because the underlying
  linguistic description can differ a lot.
\item HFST provides a way to use a morphological analyzer to construct
  a paradigm based guesser, without harmonizing tag sets.
\item Words are transformed to their corresponding analysis sets and
  the analysis sets are associated with tags and corresponding
  conditional probabilities.
\item When a previously unseen word is encountered while tagging, it
  is transformed into its set of analyses and the tag probabilities
  for that set are used.
\item For words unknown to the morphological analyzer or for words
  whose analysis set does not figure in the training data, a
  suffix-based guesser is used.
\end{itemize}

\subsection{Optimization}
% Miikka
\begin{itemize}
\item Viterbi-style optimization.
\item Beam-search for Finnish, where the tag set is huge.
\end{itemize}

\section{Applying Transducers}

\subsection{Introduction}
% Tommi

\subsection{Spellers}

The task of finite-state spell-checking is well researched and documented. It
consists mainly of two phases, identifying incorrect word forms and creating
suggestions for corrections. For incorrect word-forms there are two types of
mistakes, non-word spelling errors, such as writing \emph{cta} where \emph{cat}
is meant, and real-word spelling errors, such as writing \emph{there} where
\emph{their} is intended. The method for finding former in finite-state system
is simply applying the dictionary to the text word by word, any unrecognised
string not belonging to the language of the dictionary automaton is a non-word
spelling error. For real-word errors a statistical n-gram model or syntactic
parser is typically required\cite{}. To correct a spelling error in finite-state
system, a two-tape automaton modeling the typing errors should be applied to
the misspelt string to get set of potential corrections\cite{pirinen/lrec/2010}.
For practical purposes the error model can also be implemented as
fuzzy finite-state traversal algorithm or similar methods\cite{,}. The result
of the correction step is a set of word-forms that are correct in the
language of the spell-checking dictionary. Another related task is to rank this
set to provide the most likely corrections first for the end-user of spelling
correction system. A trivial way to perform such ranking would be to use
unigram \cite{pirinen/lrec/2010} or n-gram probabilities of the words 
\cite{mays/1991} or word-form analyses \cite{pirinen/cicling/2012}.

\subsubsection{Creating Spellers}
% Tommi

The creation of finite-state speller requires compiling of (at least) two
automata: a dictionary that contains the correctly spelt word-forms and the
error model that can rewrite misspelt word-forms into correctly spelled ones.
The former automaton can be as simple as a reference corpus, containing larger
quantities of correctly spelled words and (possibly) smaller quantities of
misspelt ones\cite{norvig/2010}. Also more elaborate dictionaries, such as
morphological analysers described in sections \ref{,,} can be used, and also
trained for spell-checking purposes with reference corpora without any big
modifications to underlying implementation\cite{pirinen/lrec/2010}.

For the error-model we can trivially construct an automaton corresponding to
Levenshtein edit distance algorithm\cite{,}. For more elaborate error models
it is possible to use hunspell algorithms as automata \cite{pirinen/il/2010} or
construct further extensions by hand \cite{pirinen/lrec/2010}. Given a possibly
aligned error corpus it is also possible to construct a weighted error model
automaton automatically \cite{}.

\subsubsection{Checking Strings and Generating Suggestions}
% Sam

\subsubsection{Ranking Suggestions}
% Tommi & Miikka

Applying the error model and the language model to the spelling error strings,
a result is typically an ordered set of corrected strings with some probability
associated to each correction. After applying the contextless error correction
described earlier it is possible to use context words and their potential
analyses to re-rank the corrections \cite{pirinen/cicling/2012}.

\subsection{Synonym and Translation Dictionaries}
% Krister

\section{Extending Transducers for Pattern Matching}
% Sam

\section{Discussion}

\section{Conclusion}

\subsubsection*{Acknowledgments}

\bibliographystyle{splncs03}

\bibliography{hfst2012}

\end{document}
% vim: set spell:
