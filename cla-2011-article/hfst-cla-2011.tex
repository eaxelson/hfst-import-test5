\documentclass[a4paper,conference]{IEEEtran}

\IEEEoverridecommandlockouts
%\usepackage{hyperref}
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[cmex10]{amsmath}
\usepackage{balance}
\usepackage{subfig}
\usepackage {graphicx}

\title{Improving Predictive Entry of Text Messages using IRC Logs}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{
\IEEEauthorblockA{\ldots\\
\ldots\\
\ldots\\
\ldots}
\and
\IEEEauthorblockA{\ldots\\
\ldots\\
\ldots\\
\ldots}
\and
\IEEEauthorblockA{\ldots\\
\ldots\\
\ldots\\
\ldots}
}



\begin{document}



%\IEEEspecialpapernotice{(Authors' pre-print draft version)}
\maketitle


\begin{abstract}

\end{abstract}

\section{Introduction}
\label{sec:introduction}

\IEEEPARstart{M}{obile} phone text messages are a hugely popular way
of communication, but mobile phones are not especially well suited for
inputing text because of their small size and often limited
keyboard. There are several technological solutions for inputing text
on mobile phones and other limited keyboard devices. This paper is
concerned with so called predictive text entry, which utilizes
redundancy in natural language in order to enable efficient text entry
using limited keyboards (typically including 12 keys).

There has been a lot of research into improving predictive text entry
e.g. (...), but the research has mainly been concerned with improving
the statistical model, or other technical aspects of the text entry
algorithm. In this paper, we investigate the role of choice of training
data for the accuracy of the text entry system. 

There has been work on improving text entry systems by training them
on actual text messages, e.g. (...). Since text messages are difficult
to come by and there are legal restrictions for using them,
open-source text entry systems require alternative sources of training
data, which yield good accuracy. In this paper, we use Internet Relay
Chat (IRC) logs, to train a predictive text input system for Finnish,
and show that this gives significant improvement compared to a
baseline system, which is trained using data from the Finnish
Wikipedia. 

To the best of our knowledge, there have not been earlier inquiries
into using IRC logs for training predictive text entry systems. IRC
log material is nevertheless very well suited for the task, since
there is a lot of material available in different languages. Like text
messages, it resembles spoken language and consists of short messages.

We evaluate our system against the predictive text entry in a number
of widely available mobile phones (...) and show that we get
comparable (better?, only slightly worse?) results. This demonstrates
that it is possible to construct an accurate predictive text entry
system without resorting to actual text message data. Even
optimization of the accuracy of the system can be accomplished without
using actual text message data.

Because Finnish is a morphologically complex language, our system uses
a morphological analyzer for Finnish Omorfi (...). The word forms
found in Omorfi are given probabilities according to their frequency
in the Finnish Wikipedia. These probabilities are combined using
similar probabilitites computed from IRC logs and the final
probability given for a word form is a combination of the probabilities
given by Omorfi and the IRC log model.

Since Omorfi is implemented as a weighted finite-state transducer, we
implemented our predictive text entry system in the weighted
finite-state framework. We used a freely available open-source C++
interface for constructing and utilizing weighted finite-state transducers,
Hfst (...).

This paper is organized as follows: In section \ref{sec:related-work},
we present earlier work in improving the accuracy of predictive text
entry systems. In section \ref{sec:methods}, we explain how to augment
a morphological analyzer with word frequencies computed from IRC logs
and how such a system is used to disambiguate between words
corresponding to an ambiguous input sequence. After this we present
the morphological analyzer, Omorfi, and the Hfst interface in section
\ref{sec:tools} and present the IRC log data used for training out model
and the text message data used for evaluation in \ref{sec:data}. We
evaluate our system in section \ref{sec:evaluation} and present some
general and closing remarks in sections \ref{sec:discussion} and
\ref{sec:conclusions}.

% - Demonstrate the relevance of the research problem.
%   * Predictive text entry works poorly, because it doesn't adequately take 
%     into account the difference between general written language and text 
%     messages.
%   * We need more realistic training data.
%   * Genuine text messages are hard to come by.
% - Instead of text messages, we use IRC logs, which can easily be harvested
%   from the internet (from the public domain?) and which ressemble text 
%   messages.
% - We claim that using IRC Logs and a dictionary we can achieve significant 
%   improvement compared to using only a morphological dictionary
% - We demonstrate that IRC logs can be used to both train and weight a 
%   predictive text entry system for text messages withput resorting to 
%   text message data even for adjusting the weights of component models.
%   (something like that...) 
% - To the best of our knowledge there have been no previous published
%   using IRC logs to train predictive text entry systems.

\section{Related Work}
\label{sec:related-work}

\begin{itemize}
\item Using genre or domain-specific text to train a NLP system is not
  a new idea.The approach has been tested in e.g. automatic
  translation (...) and tagging (...).
\item \cite{Harbusch/2003} Investigate the usefulness of a
  domain-specific lexical model in predictive text entry. They
  established that it is difficult to assemble a good enough purely
  domain-specific lexicon. According to them, the best approach is
  therefore to use a combination of a high coverage general lexicon
  and a domain-specific model, which is exactly what we have done.
\item \cite{Harbusch/2003} are concerned with building systems for very
  specific domains such as school exercises ad scientific texts. They
  do not really address the question of what would constitute
  practical training material for a general text message system. We
  are expressly interested in improving text entry using widely
  available materials.
\end{itemize}

\section{Combining a Morphological Lexicon and IRC Logs}
\label{sec:methods}

Our goal is to first combine two probabilistic lexicons, to build a
probabilistic model which (i) has broad lexical coverage and (ii)
gives a good approximation of the probabilities of word forms in text
messages. We then transform the model so that it can be used as a
machine, that takes number sequences such as "2452" as input. It
outputs the list of Finnish words that can correspond to the input,
when typed on a cell phone. The output contains only those words,
which are known to the lexicons. The words are appended with a
probability, which is computed from the probabilities given by the
lexicons used to construct the model.

One of the lexicons we use is derived from the Finnish open-source
morphological analyzer Omorfi. The other lexicon we construct from a
corpus of IRC logs.

We have chosen to implement our system using weighted finite-state
machines, partly because the morphological analyzer Omorfi is
implemented as a WFST, but also because they provide a flexible way of
combining models to build language technology applications.

\subsection{Weighted Finite-State Transducers}

%The weighted language model in our finite-state language model is based
%on morphological dictionary of the language created in traditional
%finite-state morphology framework\cite{beesley/2003}. The weights in
%this system will be basic scaled unigram weights transformed in
%finite-state form by $w = -\log \frac{f}{cs}$ where $w$ is the weight,
%$f$ is the frequency of token and $cs$ the size of corpus in
%tokens. For tokens that do not exist maximum weight of $w_{max} =
%-\log \frac{1}{cs+1}$ is used.  The probabilities are gained by
%extracting the word frequencies from a large scale corpus such as
%wikipedia~\cite{pirinen/2010/lrec}. The basic unigram weighting system
%can be fine-tuned, especially on part of unknown words, by composing
%additional weights based on e.g. morphological complexity, as
%suggested in \cite{karlsson/1992}, which can be easily modeled in
%weighted finite-state form as suggested e.g. in\cite{schiller/2005}

Finite-state transducers are a class of computational models, which
rewrite input strings to output strings \cite{beesley/2003}. A
classical example of a language technological application implemented
as finite-state transducers, are morphological analyzer, which rewrite
an input word e.g. "dog" into a set of morphological analyses
$\{$"dog+NOUN+SG", "dog+VERB+INF"$\}$.

Our system is implemented using weighted finite-state transducers
(WFSTs). These are an extension of finite-state transducers, where
every every correspondence between an input string and an output
string receives a weight (usually a floating point number). The
weights in our system represent probabilities. Akin to ordinary
transducers, WFSTs can be combined using different binary algebraic
operations or modified using unary algebraic operations to yield new
WFSTs. Our system uses three different algebraic operations:
\begin{description}
\item[Projection:] A unary operation, which  
\item[Disjunction:]
\item[composition:]
\end{description}

Our lexicons code simply Finnish words along with probabilities estimated using word frequencies in corpora.

\subsection{Combining the Component Lexicons}

%The probability weightins systems need to be scaled in combination to match and
%\ldots
% Tähän kai pitää vielä tarkentaa mitä on tehty omorfin + irkkilokipainojen
% skaalaukseen ja mitä se tarkotaa

\subsection{Using a Combination of Lexicons for Predictive Text Entry}

\section{Tools and Resources}
\label{sec:tools}

To implement the full system we have used only freely available open source
tools and resources that anyone can download from the Internet to reproduce the
results. For the finite-state system we have selected the HFST
tools\footnote{\url{http://hfst.sf.net}}, which is relatively complete
reproduction of the classical tools of finite-state
morphology\cite{beesley/2003}. Similarly we have downloaded a freely available
Finnish finite-state morphological analyser
omorfi\footnote{\url{http://home.gna.org/omorfi/}} for our language model
data\cite{pirinen/2011/nodalida}. For further training of the language model we
have used the Finnish
Wikipedia\footnote{\url{http://dumps.wikimedia.org/fiwiki/latest/}} as corpus
to acquire the unigram probabilities\cite{pirinen/2010/lrec}.

\subsection{Tools}

In our setup we use unmodified version of HFST tools for creation, manipulation
and use of finite state transducers\cite{hfst/2011}. This means that we have
not needed to prepare any specialised algorithms for application of the t9
predictive input model. This basically means that it can be used on any of
current or future finite-state systems as long as they implement needed subset
of finite-state algebra as defined in \ref{sec:methods}.

For processing of corpora we have used standard GNU tools like coreutils as
well as bash and python scripting languages. The source code of the full system
used for building, applying and evaluation of the full system is available
under free
licence\footnote{\url{http://hfst.svn.sourceforge.net/viewvc/hfst/trunk/cla-2011-article/}}.

\subsection{Data}
\label{sec:data}

For language model we have selected to use ready-made free open source
finite-state implementation of Finnish language\cite{pirinen/2011/nodalida}.
The language model here is meant for parsing running text consisting mainly of
standard written Finnish language, which is relatively far from the language
sms text messages.  To train the language model we have used
the Finnish Wikipedia data to add unigram probabilities to word forms that are
recognised by the language model we are using. 

\subsubsection{IRC Logs}
IRC (Internet Relay Chat) VIITE? is a real-time messaging network. It is mainly used for group communication, but also enables private one-on-one discussions. The group communication happens on channels, similar to chat rooms, of which some are private and require a password to enter. The IRC logs we use are from a public channel directed mainly to the members of a local student organization. The topic of the discussion varies a lot making the log quite versatile as test and teaching material.

IRC discussions tend to be rather informal, and thus the language used is casual, resembling the spoken language, as is also the case with text messages. In Finnish this  means e.g. shortening words from the end and using different word forms than formal written language does.

The IRC logs used in this research contain 385303 words after omitting everything that does not consist of letters, an apostrophe (') and a hyphen (-); the three elements that are used to form Finnish words.

\subsubsection{Text Messages}

Authentic text messages were collected for testing purposes via requests in the social media from 12 volunteers, aged between 20 and 35. The messages contain 10851 words after the same trimming that was performed to the IRC logs.

\section{Evaluation}
\label{sec:evaluation}

Our goal was to test whether adding some understanding of spoken language to the lexicon of a predictive text model improves its quality. We also aimed to find out how suitable IRC logs are for this purpose. We used a morphological analyser for Finnish as a baseline model. Our hypothesis is that the language in IRC logs, being often of casual nature, resembles the language used in text messages and can therefore be used as a source for creating models that understand spoken language.


\subsection{Creating the models and determining penalty weights}
\label{sec:weighting}
To create a model with and understanding of spoken language, we started out by separating one tenth of the IRC logs and setting it aside for testing purposes, and used the rest of the logs to build the model. We counted the frequencies of the words and built a transducer of them, containing weights based on the frequencies. PAINOJEN LASKUKAAVA? The weights were processed (…) to the form of penalty weights, where small values mean high desirability.

After creating the model for spoken language, we combined it with the baseline model, i.e. the morphological analyser. We scaled the weights of the baseline model and the spoken language model to fit the same scale by MIIKKA KERTOO JOTAIN? and tried out different ways of prioritising the spoken language compared to the literal language contained by the baseline model. We created 11 combination models, giving the spoken language a propositional weight scaling from 0.0 (no penalty weight) to 1.0 (maximum penalty weight) with an interval of 0.1. 

Both the baseline model and the combination model understanding spoken language take number sequences as an input and return an analysis of which words would match that sequence, sorted according to the penalty weights of the words. In cases where a word is recognised by both models, the one with a smaller penalty weight (i.e. better rating) will be chosen.

We tested the combination model with the one tenth of the IRC log set aside for testing. 94.37 \% of the words were successfully analysed. Of all the weighted combination models, the one with the weight 0.2 for the spoken language model and the 0.8 weight for the baseline model recognised the most words on the first try (see MIIKAN KUVA).

\subsection{Assessing the difficulty of the test material}
\label{sec:difficulty}
To ensure the test results were not merely a result of coincidentally having chosen an exceptionally easy tenth of the IRC logs, we ran the same tests for each of the other tenths as well, creating the combination models using the rest of the logs, using the optimal weighting (see \ref{sec:weighting}). The amount of the words recognised was between 93.95 and 94.99 \% in each case, with an average of 94.51 \%. This means that the original tenth of the logs used for testing is quite similar to the other tenths in terms of difficulty for the model, and we have no reason to assume the choice of the test material would significantly bias the results.

\subsection{Testing with text messages}

(Kaivataanko jostain tuloksista taulukoita? )
 
We then used the text message data for testing. 91.07 \% of the words were analysed correctly. The text message data also received the best results with the weighting 0.2 for the spoken language model and 0.8 for the baseline model, with which 75.16 \% of the words were recognised on the first attempt.

We also ran tests with the text message data on the alternative combination models created for testing the difficulty of the original combination model (see \ref{sec:difficulty}). The amount of successfully analysed words range between 91.06 \% and 91.18\%, and from 75.02 \% to 75.42 \% of the words were recognised at the first attempt. 

The results for correct first guesses have an average of 75.22 \%, with a standard deviation of 0.10 percentage points. If the results follow the normal distribution, 99.7 \% of them should be within 3 standard deviations from the average, i.e. between 74.92 \% and 75.52 \%. We do not know whether the results are normally distributed, but this gives us a rough idea of what the results are expected to look like.

% baseline -vertailu

To confirm our assumption that adding the understanding of spoken language indeed improves the quality of the results, we ran the text message test data through the baseline model to see how much the spoken language model affects the results. The difference between the results achieved with the baseline and the combined model is noticeable. The baseline gave a correct analysis for 81.37 \% of the words. Only 55.10 \% of the words were given the correct analysis at the first attempt.

Taulukko baselinen ja kombon tuloksista?

To determine the significance of the differences between the results from the baseline model and the combination model, we ran a Wilcoxon paired rank test which is suitable for data that cannot be guaranteed to follow the normal distribution. We compared the percentages of correct first attempts with the baseline model and the ten different combination models. Since the test requires equally big sets of test data, we used the baseline model result as a counterpart for each of the different combination model results. The test gave a p-value of 6.34e-05, which means that we can quite confidently say the results differ quite clearly.



\begin{figure*}[!t]
\centerline{\subfloat[The first guess is correct.]{\includegraphics[width=3.5in]
  {accuracy_first_guess.pdf}}
\hfil
\subfloat[Correct guess found among the three first guesses.]{\includegraphics[width=3.5in]
  {accuracy_first_to_third_guess.pdf}}}
\caption{The accuracy of our algorithm using different linear combinations of the weights given by the morphological analyzer and the IRC log transducer. On the x-axis we give the relative weight of the IRC log transducer and on the y-axis we give the accuracy. The dotted line gives the accuracy for the text message test material and the solid line gives the accuracy for the IRC log test material.}
\label{AccuraciesIRCMaterial}
\end{figure*}

\section{Discussion and Future Work}
\label{sec:discussion}

This work demonstrates that using simple methods we can improve a lot.\ldots

In this paper we used readily available language model geared towards parsing
running texts of literary written Finnish. It would be interesting to see if
modifying the language model towards the standard spoken Finnish dialect
might yield a significant increase in recall.

The demonstrated model only considers unigrams for probability
likelihood maximisation. It has been demonstrated that it is possible
to extend these models trivially to arbitrary n-gram and varigram
models \cite{Silfverberg/2011}, and this should be explored to see if
there's improvement for wider statistical models in task of predictive
text input for mobile text messages.

Finally we have only performed our experiment for Finnish, but we believe that
same methods will apply to at least most of the latin abjad based languages
with no modifications excepting the orthographic conventions---such as accent
dropping---on some texting cultures.

\section{Conclusion}
\label{sec:conclusions}

\ldots \balance
\section*{Acknowledgment}
Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

% We the people thank the HFST research team and the staff of University of
% Helsinki for fruity discussions as well as the anonymous reviewers for
% good suggestions.
\
\bibliographystyle{IEEEtran}
\bibliography{cla2011}




% that's all folks
\end{document}


